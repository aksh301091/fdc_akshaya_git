{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff154a0-abe5-4a30-90ba-0393bd1ffc9d",
   "metadata": {},
   "source": [
    "# Data: Ad Sales Data\n",
    "# Use Case: Revenue Prediction\n",
    "# Model: Regression Models\n",
    "\n",
    "Code link: https://www.kaggle.com/code/akshaysunil07/ad-tech-revenue-regression/notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8bfe",
   "metadata": {},
   "source": [
    "# Installing packages section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.2\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting snowflake-snowpark-python==1.9.0\n",
      "  Downloading snowflake_snowpark_python-1.9.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting fosforio\n",
      "  Downloading fosforio-1.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fosforml\n",
      "  Downloading fosforml-1.1.6-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting snowflake-connector-python[pandas]\n",
      "  Downloading snowflake_connector_python-3.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Collecting setuptools>=40.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading setuptools-72.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.1.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi<2.0.0,>=1.9 (from snowflake-connector-python[pandas])\n",
      "  Downloading cffi-1.16.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography<43.0.0,>=3.1.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading cryptography-42.0.8-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading pyOpenSSL-24.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyjwt<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pytz (from snowflake-connector-python[pandas])\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging (from snowflake-connector-python[pandas])\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from snowflake-connector-python[pandas])\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from snowflake-connector-python[pandas])\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from snowflake-connector-python[pandas])\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python[pandas])\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting platformdirs<5.0.0,>=2.6.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tomlkit (from snowflake-connector-python[pandas])\n",
      "  Downloading tomlkit-0.13.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Downloading urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "Collecting pyarrow (from snowflake-connector-python[pandas])\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "INFO: pip is looking at multiple versions of fosforml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fosforml\n",
      "  Downloading fosforml-1.1.5-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading fosforml-1.0.9-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading fosforml-1.0.8-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of fosforml to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading fosforml-1.0.7-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.5-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading fosforml-1.0.2-py3-none-any.whl.metadata (878 bytes)\n",
      "  Downloading fosforml-1.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading fosforml-1.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting requests-toolbelt==0.9.1 (from fosforml)\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting shutils==0.1.0 (from fosforml)\n",
      "  Downloading shutils-0.1.0.tar.gz (2.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting mosaic-utils (from fosforml)\n",
      "  Downloading mosaic_utils-1.0.2-py2.py3-none-any.whl.metadata (10 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting configparser (from shutils==0.1.0->fosforml)\n",
      "  Downloading configparser-7.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pymysql (from shutils==0.1.0->fosforml)\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting six>=1.5 (from python-dateutil)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pycparser (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas])\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading snowflake_snowpark_python-1.9.0-py3-none-any.whl (327 kB)\n",
      "Downloading fosforio-1.0.2-py3-none-any.whl (20 kB)\n",
      "Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading fosforml-1.0.0-py3-none-any.whl (42 kB)\n",
      "Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Downloading cffi-1.16.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (444 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Downloading cryptography-42.0.8-cp37-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-72.1.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading snowflake_connector_python-3.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading mosaic_utils-1.0.2-py2.py3-none-any.whl (70 kB)\n",
      "Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.0-py3-none-any.whl (37 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading configparser-7.0.0-py3-none-any.whl (16 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Building wheels for collected packages: shutils\n",
      "  Building wheel for shutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shutils: filename=shutils-0.1.0-py3-none-any.whl size=3275 sha256=0b204101b83c69994bfdc9e986ad66098a8ba783b0337c20cae1e5a9f1a4868e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0bwgyqe0/wheels/c7/06/1a/4df9f03d511efd19a10f2086f67c38cf14757b555f4f24bd6e\n",
      "Successfully built shutils\n",
      "Installing collected packages: sortedcontainers, pytz, asn1crypto, zipp, wheel, urllib3, tzdata, typing-extensions, tomlkit, threadpoolctl, six, setuptools, pyyaml, pyparsing, pymysql, pyjwt, pycparser, platformdirs, pillow, packaging, nvidia-nccl-cu12, numpy, kiwisolver, joblib, idna, fonttools, filelock, cycler, configparser, cloudpickle, charset-normalizer, certifi, shutils, scipy, requests, python-dateutil, pyarrow, importlib-resources, contourpy, cffi, xgboost, scikit-learn, requests-toolbelt, pandas, matplotlib, cryptography, pyOpenSSL, mosaic-utils, fosforio, snowflake-connector-python, fosforml, snowflake-snowpark-python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "mlflow 2.10.0 requires packaging<24, but you have packaging 24.1 which is incompatible.\r\n",
      "mlflow 2.10.0 requires pyarrow<16,>=4.0.0, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "mlflow 2.10.0 requires pytz<2024, but you have pytz 2024.1 which is incompatible.\r\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.0a1 which is incompatible.\r\n",
      "jupyterlab-server 2.25.4 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\r\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.3.3 which is incompatible.\r\n",
      "mosaic-ai-serving 1.0.0 requires itsdangerous==2.0.1, but you have itsdangerous 2.2.0 which is incompatible.\r\n",
      "mosaic-ai-serving 1.0.0 requires Jinja2==3.0.3, but you have jinja2 3.1.4 which is incompatible.\r\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "openapi-schema-validator 0.6.2 requires jsonschema<5.0.0,>=4.19.1, but you have jsonschema 3.2.0 which is incompatible.\r\n",
      "openapi-spec-validator 0.7.1 requires jsonschema<5.0.0,>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\r\n",
      "snowflake-ml-python 1.0.1 requires cryptography<39.0.0,>=3.1.0, but you have cryptography 42.0.8 which is incompatible.\r\n",
      "snowflake-ml-python 1.0.1 requires packaging<24,>=20.9, but you have packaging 24.1 which is incompatible.\r\n",
      "snowflake-ml-python 1.0.1 requires pandas<2,>=1.0.0, but you have pandas 2.0.0 which is incompatible.\r\n",
      "snowflake-ml-python 1.0.1 requires xgboost<2,>=1.7.3, but you have xgboost 2.1.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed asn1crypto-1.5.1 certifi-2024.7.4 cffi-1.16.0 charset-normalizer-3.3.2 cloudpickle-1.6.0 configparser-7.0.0 contourpy-1.1.1 cryptography-42.0.8 cycler-0.12.1 filelock-3.15.4 fonttools-4.53.1 fosforio-1.0.2 fosforml-1.0.0 idna-3.7 importlib-resources-6.4.0 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.7.5 mosaic-utils-1.0.2 numpy-1.24.4 nvidia-nccl-cu12-2.22.3 packaging-24.1 pandas-2.0.0 pillow-10.4.0 platformdirs-4.2.2 pyOpenSSL-24.2.1 pyarrow-17.0.0 pycparser-2.22 pyjwt-2.9.0 pymysql-1.1.1 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0 requests-2.32.3 requests-toolbelt-0.9.1 scikit-learn-1.2.1 scipy-1.10.1 setuptools-72.1.0 shutils-0.1.0 six-1.16.0 snowflake-connector-python-3.12.0 snowflake-snowpark-python-1.9.0 sortedcontainers-2.4.0 threadpoolctl-3.5.0 tomlkit-0.13.0 typing-extensions-4.12.2 tzdata-2024.1 urllib3-1.26.15 wheel-0.44.0 xgboost-2.1.1 zipp-3.19.2\r\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers-2.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel-0.44.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-1.26.15.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit-0.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl-3.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools-72.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyYAML-6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing-3.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pymysql already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyMySQL-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/jwt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyJWT-2.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser-2.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs-4.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow-10.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/nvidia already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/nvidia_nccl_cu12-2.22.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.24.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver-1.4.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib-1.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fontTools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fonttools-4.53.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock-3.15.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler-0.12.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/backports already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/configparser-7.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle-1.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.7.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/shutils already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/shutils-0.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy-1.10.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.32.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scripts already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/benchmarks already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow-17.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/examples already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cmake_modules already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources-6.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_cffi_backend.cpython-38-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost-2.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn-1.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_toolbelt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_toolbelt-0.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.7.5-py3.8-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.7.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography-42.0.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/OpenSSL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyOpenSSL-24.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mosaic_utils already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mosaic_utils-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforio-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_connector_python-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforml-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0-py3.11-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlflow 2.10.0 requires packaging<24, but you have packaging 24.1 which is incompatible.\n",
      "mlflow 2.10.0 requires pytz<2024, but you have pytz 2024.1 which is incompatible.\n",
      "fosforml 1.0.0 requires cloudpickle==1.6.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "fosforml 1.0.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "fosforml 1.0.0 requires urllib3==1.26.15, but you have urllib3 1.26.19 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.0a1 which is incompatible.\n",
      "jupyterlab-server 2.25.4 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.7.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.3.3 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires itsdangerous==2.0.1, but you have itsdangerous 2.2.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Jinja2==3.0.3, but you have jinja2 3.1.4 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.7.5 which is incompatible.\n",
      "openapi-schema-validator 0.6.2 requires jsonschema<5.0.0,>=4.19.1, but you have jsonschema 3.2.0 which is incompatible.\n",
      "openapi-spec-validator 0.7.1 requires jsonschema<5.0.0,>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires cryptography<39.0.0,>=3.1.0, but you have cryptography 42.0.8 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires packaging<24,>=20.9, but you have packaging 24.1 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires pandas<2,>=1.0.0, but you have pandas 2.0.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires xgboost<2,>=1.7.3, but you have xgboost 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: urllib3 1.26.15\n",
      "Uninstalling urllib3-1.26.15:\n",
      "  Successfully uninstalled urllib3-1.26.15\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting urllib3==1.26.15\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Installing collected packages: urllib3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforml 1.0.0 requires cloudpickle==1.6.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "fosforml 1.0.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "snowflake-snowpark-python 1.9.0 requires cloudpickle<=2.0.0,>=1.6.0; python_version < \"3.11\", but you have cloudpickle 2.2.1 which is incompatible.\n",
      "jupyterlab-server 2.25.4 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.7.5 which is incompatible.\n",
      "openapi-spec-validator 0.7.1 requires jsonschema<5.0.0,>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires cryptography<39.0.0,>=3.1.0, but you have cryptography 42.0.8 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires pandas<2,>=1.0.0, but you have pandas 2.0.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires xgboost<2,>=1.7.3, but you have xgboost 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy!=1.24.0,>=1.20 (from seaborn)\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas>=1.2->seaborn)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m219.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m280.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m279.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m307.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m611.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m351.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: pytz, zipp, tzdata, six, pyparsing, pillow, packaging, numpy, kiwisolver, fonttools, cycler, python-dateutil, importlib-resources, contourpy, pandas, matplotlib, seaborn\n"
     ]
    }
   ],
   "source": [
    "# Installing packages set for without init script\n",
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio fosforml numpy pandas matplotlib scikit-learn xgboost python-dateutil \n",
    "#!pip install tqdm \n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a4ab2",
   "metadata": {},
   "source": [
    "# Restart and clear outputs\n",
    "\n",
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "#from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from time import sleep\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999d5f2",
   "metadata": {},
   "source": [
    "# Importing data from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e536f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fosforio import snowflake\n",
    "#from fosforio import get_dataframe\n",
    "snowflake.get_connection(connection_name=\"ME_AD_SALES_CXN\")\n",
    "#df = get_dataframe(\"AD_SALES_IMP\")\n",
    "df_all = get_dataframe(\"AD_TECH_INPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe(\"AD_SALES_IMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb41bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns = df.columns.str.lower()\n",
    "#df_all.columns = df_all.columns.str.lower()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db2869-09aa-4132-8972-a3cc74bb0263",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fc2cd-8e2e-4e27-b288-87a549556779",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['AD_DATE', 'SITE_ID','ADVERTISER_ID', 'ORDER_ID','AD_TYPE', 'AD_FORMAT', 'AD_MEDIA_TYPE',\n",
    "         'DEVICE_TYPE', 'CITY', 'LINE_ITEM_GROUP', 'LINE_ITEM_TYPE', 'MONETIZATION_CHANNEL','OS_TYPE']\n",
    "scat_col = ['SITE_ID','AD_TYPE', 'AD_FORMAT', 'DEVICE_TYPE', 'ADVERTISER_ID',\n",
    "            'LINE_ITEM_GROUP', 'LINE_ITEM_TYPE', 'OS_TYPE','MONETIZATION_CHANNEL']\n",
    "\n",
    "num_col=list(df_all.select_dtypes(np.number).columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d3e90d",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df_all.isnull(),cbar=False,cbar_kws={'color':'r'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e0244-4680-44bf-9dfb-a67f5f61eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2, figsize=(14,12))\n",
    "axes_ = [axes_row for axes in ax for axes_row in axes]\n",
    "\n",
    "for i,col in enumerate(scat_col):\n",
    "    sns.countplot(data=df_all,x=col,ax=axes_[i])\n",
    "    if col=='ADVERTISER_ID':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f37132-8305-4793-8c92-f8828d07970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_col:\n",
    "    if i!='TOTAL_REVENUE':\n",
    "        sns.scatterplot(data=df_all,x=i,y='TOTAL_REVENUE')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb091da-8e4e-46a6-b24f-af4eb795f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266fcc2-2b3b-47a2-9dcb-cf2c2efb53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+col+' with total_revenue'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['TOTAL_REVENUE'],x=df_all[col])\n",
    "    if col=='ADVERTISER_ID':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88c3cf-8b3f-490d-8cdd-abef798c12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+ col +' with total_impressions'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['TOTAL_IMPRESSIONS'],x=df_all[col],)\n",
    "    if col=='ADVERTISER_ID':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867e33c-830f-4478-89f8-10dc9e3c7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_col:\n",
    "    df_all[i]=df_all[i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f35e75-ff39-485a-a87d-f01ff77b4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['AD_UNIT_ID','REVENUE_SHARE_PERCENT','AD_TYPE_ID','SITE_ID','ADVERTISER_ID',\n",
    "        'AD_DATE','GEO_ID','ORDER_ID', 'AD_TYPE', 'AD_FORMAT', 'AD_MEDIA_TYPE', 'LINE_ITEM_GROUP',\n",
    "            'CITY', 'CITY_CODE', 'DEVICE_CATEGORY_ID', 'LINE_ITEM_TYPE_ID', 'OS_ID',\n",
    "       'MONETIZATION_CHANNEL_ID','POPULATION', 'CITY_LAT', 'CITY_LON'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f89ae-6bbc-4d63-8624-3f37c9c04fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_all.select_dtypes(object).columns:\n",
    "    pd.crosstab(df_all['MONETIZATION_CHANNEL'],df_all[i]).plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab7196b",
   "metadata": {},
   "source": [
    "# Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9147704-4046-457d-8ca2-c7235c0c0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = df_all.drop('TOTAL_REVENUE',axis=1)\n",
    "y = df_all['TOTAL_REVENUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361d941-0784-4adc-aed8-69adba480dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(Xd,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f62ad3-0adc-418b-8d21-e558d18a7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_col = ['TOTAL_IMPRESSIONS', 'VIEWABLE_IMPRESSIONS', 'MEASURABLE_IMPRESSIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2))\n",
    "        ]), pc_col),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['DEVICE_TYPE', 'LINE_ITEM_TYPE', 'OS_TYPE',\n",
    "       'MONETIZATION_CHANNEL'])\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\n",
    "    {\n",
    "        'name': 'RandomForestRegressor',\n",
    "        'regressor': [RandomForestRegressor()],\n",
    "        'regressor__n_estimators': [50],\n",
    "        'regressor__max_depth': [10],\n",
    "        'regressor__min_samples_split': [2],\n",
    "        'regressor__min_samples_leaf': [1],\n",
    "        'regressor__bootstrap': [True]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb07eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = []\n",
    "for model_params in models:\n",
    "    model_name = model_params.pop('name')  # Extract the model name\n",
    "    grid_search = GridSearchCV(pipeline, model_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    best_estimators.append(best_estimator)\n",
    "    print(f\"Training completed for model {model_name}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    joblib.dump(best_estimator, f'best_model_{model_name}.pkl')\n",
    "    print(f\"Best model {model_name} saved to best_model_{model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for estimator in best_estimators:\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    results.append({\n",
    "        'model': estimator.named_steps['regressor'].__class__.__name__,\n",
    "        'best_params': estimator.named_steps['regressor'].get_params(),\n",
    "        'mse': mse,\n",
    "        'r2': r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['PREDICTED_REVENUE'] = best_estimator.predict(Xd)\n",
    "df_copy['PREDICTED_REVENUE'] = best_estimator.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27330f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "\n",
    "print(df_copy['PREDICTED_REVENUE'].sum())\n",
    "print(df_copy['TOTAL_REVENUE'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4501ef",
   "metadata": {},
   "source": [
    "# Pushing Model output to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark.session import Session\n",
    "user = os.getenv(\"user\")\n",
    "warehouse = os.getenv(\"warehouse\")\n",
    "schema= os.getenv(\"schema\")\n",
    "database = os.getenv(\"database\")\n",
    "role =  os.getenv(\"role\")\n",
    "account =  os.getenv(\"account\")\n",
    "password= os.getenv(\"password\")\n",
    "\n",
    "connection_params = dict(user=user, \n",
    "                         password=password, \n",
    "                         account=account, \n",
    "                         warehouse=warehouse, \n",
    "                         database=database,\n",
    "                         schema=schema, \n",
    "                         role=role)\n",
    "\n",
    "session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "session.sql('use warehouse {};'.format(warehouse)).collect()\n",
    "\n",
    "session.sql('use database {};'.format(database)).collect()\n",
    "\n",
    "session.sql('use schema {}.{};'.format(database, schema)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowflake = session.createDataFrame(df_copy.values.tolist(),\n",
    "        schema = df_copy.columns.tolist())\n",
    "\n",
    "df_snowflake.write.mode(\"overwrite\").save_as_table(\"ME_DB.ME_AD_SALES_SCHEMA.AD_TECH_OUTPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f999a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f5ae1",
   "metadata": {},
   "source": [
    "# Model Registrartion using fosforml SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snowpark lib\n",
    "from snowflake.snowpark import Session\n",
    "from fosforio import snowflake\n",
    "from sklearn.pipeline import Pipeline\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "\n",
    "    import json\n",
    "    payload = request.json[\"payload\"]\n",
    "    if isinstance(request.json[\"payload\"],str):\n",
    "        payload_data = eval(payload)\n",
    "        if isinstance(payload_data['TOTAL_IMPRESSIONS'], int):\n",
    "                data_json = eval(payload)\n",
    "                data = pd.DataFrame([data_json])\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].to_list()[0]\n",
    "        elif isinstance(payload_data['TOTAL_IMPRESSIONS'], dict):\n",
    "                data = pd.DataFrame(eval(payload))\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].tolist()\n",
    "        elif isinstance(payload_data['TOTAL_IMPRESSIONS'], list):\n",
    "                data = pd.DataFrame(payload_data)\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction.tolist()\n",
    "    return \"This method is not allowed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e082e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1:3].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ec1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42572f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64668451",
   "metadata": {},
   "source": [
    "# Sample Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "model_reg = register_model(best_estimator,\n",
    "               score, \n",
    "               name=\"Ad_Sales_Prediction_Model\", \n",
    "               description=\"Ad_Sales_Prediction_RandomForest_Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"regression\",\n",
    "               #init_script=\"\\\\n pip install fosforml \\\\n pip install fosforio[snowflake] \\\\n pip install sklearn\\\\n pip install snowflake-connector-python[pandas]\",\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install fosforio[snowflake] \\\\n pip install seaborn \\\\n pip install snowflake-connector-python[pandas] \\\\n pip install joblib==1.3.2 scikit-learn=1.3.2\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred_test,\n",
    "               #prob=y_prob,\n",
    "               features=X_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69572d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa330b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea986e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4907e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526cfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
