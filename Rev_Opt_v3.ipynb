{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0e4ded",
   "metadata": {},
   "source": [
    "# Price Optimization for Hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fb829",
   "metadata": {},
   "source": [
    "# Getting snowflake related packages installed and imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"snowflake-connector-python[pandas]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade --q snowflake-snowpark-python==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4106af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fosforio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac29d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fosforml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab926a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f664a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb297fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe713d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b648828",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c504d4e",
   "metadata": {},
   "source": [
    "# Restart kernal and continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14007d14",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba1948d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cryptography.__about__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Session\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/301f4977-676a-4c39-9ca7-6a54313650a1/3.8/snowflake/snowpark/__init__.py:46\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION\n\u001b[1;32m     43\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m VERSION \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_job\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncJob\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolumn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CaseExpr, Column\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/301f4977-676a-4c39-9ca7-6a54313650a1/3.8/snowflake/snowpark/async_job.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterator, List, Literal, Optional, Union\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pandas\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyzer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyzer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_scan_statement\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyzer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowflake_plan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Query\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NullHandler\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SnowflakeConnection\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcursor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictCursor\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdbapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     BINARY,\n\u001b[1;32m     23\u001b[0m     DATETIME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     TimestampFromTicks,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/connection.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generator, Iterable, Iterator, NamedTuple, Sequence\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_backend\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masymmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrsa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RSAPrivateKey\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/301f4977-676a-4c39-9ca7-6a54313650a1/3.8/cryptography/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This file is dual licensed under the terms of the Apache License, Version\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 2.0, and the BSD License. See the LICENSE file in the root of this repository\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# for complete details.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__about__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __author__, __copyright__, __version__\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__author__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__copyright__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cryptography.__about__'"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e006c736",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cryptography.__about__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write_pandas\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NullHandler\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SnowflakeConnection\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcursor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictCursor\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdbapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     BINARY,\n\u001b[1;32m     23\u001b[0m     DATETIME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     TimestampFromTicks,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/connection.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generator, Iterable, Iterator, NamedTuple, Sequence\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_backend\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhazmat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitives\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masymmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrsa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RSAPrivateKey\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/301f4977-676a-4c39-9ca7-6a54313650a1/3.8/cryptography/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This file is dual licensed under the terms of the Apache License, Version\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 2.0, and the BSD License. See the LICENSE file in the root of this repository\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# for complete details.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__about__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __author__, __copyright__, __version__\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__author__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__copyright__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cryptography.__about__'"
     ]
    }
   ],
   "source": [
    "from snowflake.connector.pandas_tools import write_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "473b3b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection manager service url initialised to http://fdc-project-manager:80/project-manager\n",
      "If you need to update its value then update the variable CONNECTION_MANAGER_BASE_URL in os env.\n"
     ]
    }
   ],
   "source": [
    "from fosforio import snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81490294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd0c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24edc148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-3c0sxlnw because the default path (/home/mosaic-ai/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836d8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from time import sleep\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e03df6c",
   "metadata": {},
   "source": [
    "# Getting data from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b307b6ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection details fetched: {'params': {'READER': {'connectionId': '73423620-7e1f-47a2-b9c5-b37408757323', 'connectionSources': {'sourceId': '210d73c1-4da7-487d-8a5c-05c8d2025269', 'connectionType': 'SNOWFLAKE', 'sourceName': 'RDBMS', 'enable': 1, 'displayName': 'SNOWFLAKE', 'displayOrder': 5.0}, 'createdBy': 'ms.akshaya@fosfor.com', 'createdOn': '2024-05-24T10:53:33.084+00:00', 'updatedOn': '2024-06-06T07:18:09.475+00:00', 'name': 'TTH_REV_OPT_CXN', 'autosyncable': False, 'autopublishable': False, 'frequency': None, 'assetConfigurations': [], 'publishableNodes': [], 'autoPublishableNodes': None, 'isPrivate': False, 'isExpired': False, 'autoSyncFrequency': None, 'application': None, 'sourceDataRefreshFrequency': None, 'defaultDb': 'TTH_DB', 'defaultSchema': 'TTH_REV_OPT_SCHEMA', 'recommendedPrivileges': {'DATA_MODULE': {'usage_on_schema': True, 'usage_on_database': True, 'create_table_on_schema': True, 'select_insert_update_truncate_delete_ref_on_tables': True}, 'INSIGHT_MODULE': {}, 'DECISION_MODULE': {'grant_on_warehouse_usage_to_role': True, 'grant_on_schema_to_role': True, 'create_stage_internal': True, 'create_udfs': True, 'grant_on_database_to_role': True, 'create_store_procedure': True}}, 'roleDetails': {'selectedStandardWarehouse': 'FOSFOR_SOLUTIONS_WH', 'selectedSnowparkOptimized': '', 'standardWarehouse': ['FOSFOR_SOLUTIONS_WH'], 'snowpark_optimized_warehouse': []}, 'dbPassword': 'Password@2023', 'port': None, 'ipAddress': None, 'dbUserName': 'Akshaya', 'sslEnable': False, 'token': None, 'client_secret': None, 'client_id': None, 'accountName': 'ug94937', 'region': 'us-east4', 'wareHouse': 'FOSFOR_SOLUTIONS_WH', 'cloudPlatform': 'gcp', 'role': 'AKSHAYA', 'privateKey': None, 'passPhrase': None, 'authenticationType': 'dbPassword', 'clientId': None, 'clientSecret': None, 'tokenUrl': None, 'scopeUrl': None, 'connectionUrl': 'https://ug94937.us-east4.gcp.snowflakecomputing.com'}}}\n",
      "Ex: No module named 'cryptography.__about__'\n",
      "Exception occurred in getting snowflake connection: Exception occurred in creating snowflake connection: None\n"
     ]
    }
   ],
   "source": [
    "# To get snowflake connection object with a default snowflake connection created by the user, if available.\n",
    "snowflake.get_connection(\"TTH_REV_OPT_CXN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a65ef799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection details fetched: {'params': {'READER': {'schema': 'TTH_REV_OPT_SCHEMA', 'cloudPlatform': 'gcp', 'role': '\"AKSHAYA\"', 'clientId': None, 'tokenUrl': None, 'scopeUrl': None, 'type': 'RDBMS', 'wareHouse': 'FOSFOR_SOLUTIONS_WH', 'accountId': 'ug94937', 'privateKey': None, 'password': 'Password@2023', 'database': 'TTH_DB', 'tables': 'BOOKINGS_TRANSFORMED', 'sub_type': 'SNOWFLAKE', 'subType': 'SNOWFLAKE', 'clientSecret': None, 'authenticationType': 'dbPassword', 'rowCount': 10, 'region': 'us-east4', 'user': 'Akshaya', 'applicationName': 'FOSFOR', 'passPhrase': None}}, 'url': 'http://connectors-backend-service/connectors/v1/connectors/metadata', 'access': True, 'errorMsg': None, 'values': {}}\n",
      "Ex: No module named 'cryptography.__about__'\n",
      "Exception occurred in reading data_frame from snowflake connection: Exception occurred in creating snowflake connection: None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m snowflake\u001b[38;5;241m.\u001b[39mget_dataframe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOOKINGS_TRANSFORMED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df = snowflake.get_dataframe(\"BOOKINGS_TRANSFORMED\")\n",
    "df['ADR']= round(df['ADR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download star schema tables\n",
    "meal = \n",
    "customer = \n",
    "channel = \n",
    "room = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98990657",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"reserved_room_type\", y=\"adr\", hue= 'is_canceled', color=\".8\", linecolor=\"#137\", linewidth=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "quartiles_data = df.groupby(['hotel', 'reserved_room_type'])['adr'].agg(\n",
    "    adr_mean='mean',\n",
    "    adr_median='median',\n",
    "    adr_q01=lambda x: x.quantile(0.10),\n",
    "    adr_q1=lambda x: x.quantile(0.25),\n",
    "    adr_q2=lambda x: x.quantile(0.50),\n",
    "    adr_q3=lambda x: x.quantile(0.75),\n",
    "    adr_q4=lambda x: x.quantile(1.00)\n",
    ").reset_index()\n",
    "print(quartiles_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the quartiles data with the original data\n",
    "merged_data = pd.merge(df, quartiles_data, on=['hotel', 'reserved_room_type'])\n",
    "\n",
    "print(\"\\nMerged Data:\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = merged_data[(merged_data['adr'] > merged_data['adr_q01']) & \n",
    "                            (merged_data['adr'] < merged_data['adr_q4'])]\n",
    "\n",
    "print(\"\\nFiltered Data:\")\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be354cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming some column names\n",
    "filtered_data.rename(columns = {'arrival_date_transformed':'arrival_date', \n",
    "                                'reservation_status_date_transformed':'reservation_date',\n",
    "                                'arrival_date_year':'year','arrival_date_week_number': 'week', 'arrival_date_day_of_month': 'dom', \n",
    "                                'total_stay_nights': 'total_rns',\n",
    "                                'stays_in_weekend_nights':'weekend_nights', 'stays_in_week_nights': 'week_nights',\n",
    "                                'reserved_room_type': 'room_type', 'customer_type':'cust_type', 'ADR':'adr'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ae5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=filtered_data, x=\"room_type\", y=\"adr\", hue= 'is_canceled', color=\".8\", linecolor=\"#137\", linewidth=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=filtered_data, x=\"room_type\", y=\"adr\", hue= 'market_segment', \n",
    "            fill=False, gap=.1, linecolor=\"#137\", linewidth=.75, color= 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined column for the plot\n",
    "filtered_data['Group'] = filtered_data['hotel'] + ' - ' + filtered_data['room_type']\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Create boxplot\n",
    "sns.boxplot(x='Group', y='adr', data=filtered_data)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Boxplot of ADR by Hotel and Reserved Room Type')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('adr')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e978f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined column for the plot\n",
    "filtered_data['Group3'] = filtered_data['room_type'] + ' - ' + filtered_data['reservation_status']\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Create boxplot\n",
    "sns.boxplot(x='Group3', y='adr', data=filtered_data)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Boxplot of ADR by CANCELED and Reserved Room Type')\n",
    "plt.xlabel('Group3')\n",
    "plt.ylabel('adr')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29218ea6",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf15b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing cancelled transactions to model based on transactions that customers preferred to actually complete\n",
    "df0 = filtered_data[(filtered_data['is_canceled'] == 0) & (filtered_data['reservation_status'] !='No-Show')] \n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99536bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding what market segments need to be considered\n",
    "df0.groupby(['hotel','room_type','market_segment']).agg({'adr':'mean','reservation_date':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f8712a",
   "metadata": {},
   "source": [
    "#We will filter for room _types A,D,E and will filter OUT \"Complementary\" market_segment. retain both City and resort hotel types.\n",
    "##\"For our pricing model, we need to count the frequency of each price point\n",
    "\n",
    "##Moreover, Hotels have different room types with different prices. To create our pricing model, we need to optimize the room type level. We are interested in the room type reserved as this captures the price the guest was willing to pay for that room type. It is common for hotels to overbook the lower room types and give free upgrades to higher room types. Therefore, any pricing analysis must be done at the reserved room type and not the stayed room type.\n",
    "\n",
    "##Unfortunately, there is not much description of the reserved room type, but by looking at the price points, we can infer that A &B are the lowest price points. The rest of the room types command a higher ADR, which means they likely are upgraded rooms. In another workbook, we will explore how to price those premium rooms, but for the moment, let's focus on room types A & D, E.\n",
    "\n",
    "#filter data to only Direct and Online TA and room typ A&B\n",
    "##Create individual datasets for City, Resort, room types: A,D,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = df0[(df0['market_segment'] != 'Complementary') & (df0['market_segment'] != 'Corporate') \n",
    "#           & (df0['market_segment'] !='Aviation')]\n",
    "data1 = df0[~df0['market_segment'].isin(['Complementary', 'Corporate', 'Aviation'])]\n",
    "#data1 = df0[(df0['room_type'] == 'A') |(df0['room_type'] == 'D') | (df0['room_type'] == 'E')]\n",
    "data1.room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf42531",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.market_segment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031841de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding what market segments need to be considered\n",
    "data1.groupby(['hotel','room_type','market_segment']).agg({'adr':'mean','reservation_date':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b66650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "data1.groupby(['arrival_date']).agg({'adr':'mean','reservation_date':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf489a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unrequired columns\n",
    "data2 = data1.drop(['tally_days', 'deposit_type', 'assigned_room_type','is_canceled','adults', 'children', 'babies', \n",
    "                   'avg_rooms_per_night',\n",
    "                   'meal', 'country', 'distribution_channel', 'previous_bookings_not_canceled','deposit_type',\n",
    "                   'days_in_waiting_list', 'reservation_status_date', 'previous_cancellations','expected_arrival_date',\n",
    "                   'lead_time','total_room_nights','adr_mean','adr_median','adr_q01','adr_q1' ,'adr_q2','adr_q3','adr_q4',                       \n",
    "                   'Group','Group3'], axis =1)\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming some column names\n",
    "# data1.rename(columns = {'ARRIVAL_DATE_TRANSFORMED':'arrival_date', 'RESERVATION_STATUS_DATE_TRANSFORMED':'reservation_date',\n",
    "#                        'HOTEL':'hotel', 'ARRIVAL_DATE_YEAR':'year','MONTH':'month', \n",
    "#                       'ARRIVAL_DATE_WEEK_NUMBER': 'week', 'ARRIVAL_DATE_DAY_OF_MONTH': 'dom', \n",
    "#                       'RESERVATION_STATUS': 'reservation_status', 'TOTAL_STAY_NIGHTS': 'total_rns',\n",
    "#                       'STAYS_IN_WEEKEND_NIGHTS':'weekend_nights', \n",
    "#                       'STAYS_IN_WEEK_NIGHTS': 'week_nights','TOTAL_GUESTS': 'total_guests','MARKET_SEGMENT':'market_segment', \n",
    "#                       'RESERVED_ROOM_TYPE': 'room_type', 'CUSTOMER_TYPE':'cust_type', 'ADR':'adr'}, inplace = True) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9704628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "data2.groupby(['arrival_date']).agg({'adr':'mean','hotel':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a16e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating separate tables for Optimizing models\n",
    "ca = data2[(data2['hotel'] == 'City Hotel') & (data2['room_type'] == 'A')]\n",
    "cd = data2[(data2['hotel'] == 'City Hotel') & (data2['room_type'] == 'D')]\n",
    "ce = data2[(data2['hotel'] == 'City Hotel') & (data2['room_type'] == 'E')]\n",
    "ra = data2[(data2['hotel'] == 'Resort Hotel') & (data2['room_type'] == 'A')]\n",
    "rd = data2[(data2['hotel'] == 'Resort Hotel') & (data2['room_type'] == 'D')]\n",
    "re = data2[(data2['hotel'] == 'Resort Hotel') & (data2['room_type'] == 'E')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c84adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "ca.groupby(['arrival_date']).agg({'adr':'mean','hotel':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e89b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "cd.groupby(['arrival_date']).agg({'adr':'mean','hotel':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adf01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "ce.groupby(['arrival_date']).agg({'adr':'mean','hotel':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "ra.groupby(['arrival_date']).agg({'adr':'mean','hotel':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5014852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bcfb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "rd.groupby(['arrival_date']).agg({'adr':'mean','hotel':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d41d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking num dates\n",
    "re.groupby(['arrival_date']).agg({'adr':'mean','hotel':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9636d80",
   "metadata": {},
   "source": [
    "# Data transformation to disaggregate dates\n",
    "# For Full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_transform = data2[['hotel','room_type','arrival_date','total_rns','adr']]\n",
    "data_to_transform.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to store the data by stay date\n",
    "expanded_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the expected arrival date\n",
    "##Need to convert with hotel, room type columns\n",
    "for _, row in data_to_transform.iterrows():\n",
    "    # Get the number of stay dates for the current booking\n",
    "    num_stay_dates = row['total_rns']\n",
    "    \n",
    "    #Create a row for each stay date\n",
    "    expanded_booking = pd.DataFrame({\\\n",
    "        'hotel': row['hotel'],\n",
    "        'room_type' : row ['room_type'],                             \n",
    "        'arrival_date': pd.date_range(start=row['arrival_date'], periods=num_stay_dates),\n",
    "        'total_rns': 1,\n",
    "        'adr': row['adr']\n",
    "    })                                \n",
    "    # Append the stay date information to the new dataframe\n",
    "    expanded_df = pd.concat([expanded_df, expanded_booking], ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the final dataframe by date\n",
    "expanded_df = expanded_df.sort_values('adr')\n",
    "expanded_df = expanded_df.reset_index(drop=True)\n",
    "expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be662c1a",
   "metadata": {},
   "source": [
    "## Building seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "holiday_dates = holidays.CountryHoliday('PT', years=[2020,2021,2022,2023])\n",
    "holidays = {\n",
    "    expected_arrival_date: name\n",
    "    for expected_arrival_date, name in holiday_dates.items()\n",
    "    if name in ['Ano Novo', 'Páscoa', 'Dia de Natal']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename holiday columns\n",
    "expanded_df = expanded_df.rename({'Ano Novo':'new_year','Páscoa':'easter','Dia de Natal':'christmas'},axis=1)\n",
    "\n",
    "holidays = {datetime.date(2023, 1, 1): 'new_year',\n",
    " datetime.date(2023, 3, 27): 'easter',\n",
    " datetime.date(2023, 12, 25): 'christmas',\n",
    " datetime.date(2022, 1, 1): 'new_year',\n",
    " datetime.date(2022, 4, 16): 'easter',\n",
    " datetime.date(2022, 12, 25): 'christmas',\n",
    " datetime.date(2021, 1, 1): 'new_year',\n",
    " datetime.date(2021, 4, 5): 'easter',\n",
    " datetime.date(2021, 12, 25): 'christmas',\n",
    " datetime.date(2020, 1, 1): 'new_year',\n",
    " datetime.date(2020, 4, 5): 'easter',\n",
    " datetime.date(2020, 12, 25): 'christmas'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3247196",
   "metadata": {},
   "source": [
    "# updated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_holiday_dates(start_year, end_year):\n",
    "    holidays = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        holidays[datetime.date(year, 1, 1)] = 'new_year'\n",
    "        easter_date = pd.to_datetime(calendar().easter(year)).date()\n",
    "        holidays[easter_date] = 'easter'\n",
    "        holidays[datetime.date(year, 12, 25)] = 'christmas'\n",
    "    return holidays\n",
    "\n",
    "generate_holiday_dates(2020, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faaf989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre and post ranges for each holiday\n",
    "pre_range_offset = {'new_year': relativedelta(days=-1),\n",
    "                    'easter': relativedelta(days=-2),\n",
    "                    'christmas': relativedelta(days=-3)}\n",
    "\n",
    "post_range_offset = {'new_year': relativedelta(days=1),\n",
    "                     'easter': relativedelta(days=2),\n",
    "                     'christmas': relativedelta(days=3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ddae79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b465f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for each holiday\n",
    "for holiday in holidays.values():\n",
    "    expanded_df[holiday] = 0\n",
    " \n",
    " # Set the holiday columns to 1 for matching dates\n",
    "for arrival_date, name in holidays.items():\n",
    "    expanded_df.loc[expanded_df['arrival_date'] == arrival_date, name] = 1\n",
    "\n",
    "    # Set the holiday columns to 1 for pre and post dates\n",
    "    pre_offset = pre_range_offset.get(name)\n",
    "    if pre_offset:\n",
    "        pre_date = pd.to_datetime(arrival_date) + pre_offset\n",
    "        expanded_df.loc[expanded_df['arrival_date'] == pre_date.strftime('%Y-%m-%d'), name] = 1\n",
    "\n",
    "    post_offset = post_range_offset.get(name)\n",
    "    if post_offset:\n",
    "        post_date = pd.to_datetime(arrival_date) + post_offset\n",
    "        expanded_df.loc[expanded_df['arrival_date'] == post_date.strftime('%Y-%m-%d'), name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check\n",
    "expanded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1028e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f23fa498",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd218944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dow, month to data\n",
    "expanded_df['dow'] = expanded_df.arrival_date.dt.strftime('%A')\n",
    "expanded_df['month'] = expanded_df.arrival_date.dt.strftime('%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fdf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check\n",
    "expanded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116102e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PRICING MODEL 1 (WITHOUT HOLIDAYS)\n",
    "#Remove holidays for our main model\n",
    "non_holidays = expanded_df[expanded_df[['new_year', 'easter', 'christmas']].sum(axis=1) == 0]\n",
    "non_holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece32944",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Our optimization will be done at the DOW and Month Level. As a reminder, we are trying to model the relationship between Price and Demand so that we can answer the below question: if I charge X , how many rooms will I sell? To begin with, we need to get the demand levels for each DOW and month as well as create a table counting how many times each price point appears for each DOW and month.\n",
    "\n",
    "##ADD HOTEL, ROOM TYPE TO GROUPINGS\n",
    "daily_rns = non_holidays.groupby(['arrival_date','dow','month']).agg({'total_rns':'sum'}).reset_index() # get total stays per day\n",
    "daily_rns = daily_rns.groupby(['dow','month']).agg({'total_rns':['sum','mean','median']}).reset_index() # get Rns metrics by Dow & Month\n",
    "daily_rns.columns = ['_'.join(col) for col in daily_rns.columns] #remove multi level column\n",
    "daily_rns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45117dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Counting rate frequency\n",
    "##In the next step, we will count how often each adr (price the guest paid) appears for each DOW and month.\n",
    "# create rate frequency table\n",
    "adr_frequency = non_holidays.groupby(['dow','month','adr']).agg({'total_rns':'sum'})\n",
    "adr_frequency.reset_index(inplace=True)\n",
    "adr_frequency.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad8896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86f94deb",
   "metadata": {},
   "source": [
    "# Data transformation to dis-aggregate dates- \n",
    "# For City Hotel room type A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_data_to_transform = ca[['hotel','room_type','arrival_date','total_rns','adr']]\n",
    "ca_data_to_transform.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to store the data by stay date\n",
    "ca_expanded_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the expected arrival date\n",
    "##Need to convert with hotel, room type columns\n",
    "for _, row in ca_data_to_transform.iterrows():\n",
    "    # Get the number of stay dates for the current booking\n",
    "    num_stay_dates = row['total_rns']\n",
    "    \n",
    "    #Create a row for each stay date\n",
    "    ca_expanded_booking = pd.DataFrame({\n",
    "        'hotel': row['hotel'],\n",
    "        'room_type' : row ['room_type'], \n",
    "        'arrival_date': pd.date_range(start=row['arrival_date'], periods=num_stay_dates),\n",
    "        'total_rns': 1,\n",
    "        'adr': row['adr'] \n",
    "    })\n",
    "    # Append the stay date information to the new dataframe\n",
    "    ca_expanded_df = pd.concat([ca_expanded_df, ca_expanded_booking], ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ba954",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_expanded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_expanded_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the final dataframe by date\n",
    "ca_expanded_df = ca_expanded_df.sort_values('arrival_date')\n",
    "ca_expanded_df = ca_expanded_df.reset_index(drop=True)\n",
    "ca_expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_expanded_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
