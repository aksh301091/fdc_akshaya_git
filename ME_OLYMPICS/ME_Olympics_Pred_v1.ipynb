{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9559c1a",
   "metadata": {},
   "source": [
    "## Olympics Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92494cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pip\n",
      "  Downloading pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.1.2\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting snowflake-snowpark-python==1.9.0\n",
      "  Downloading snowflake_snowpark_python-1.9.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fosforio\n",
      "  Downloading fosforio-1.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fosforml\n",
      "  Downloading fosforml-1.1.6-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting holidays\n",
      "  Downloading holidays-0.53-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting faker\n",
      "  Downloading Faker-26.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting snowflake-connector-python[pandas]\n",
      "  Downloading snowflake_connector_python-3.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m240.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setuptools>=40.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading setuptools-71.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.1.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi<2.0.0,>=1.9 (from snowflake-connector-python[pandas])\n",
      "  Downloading cffi-1.16.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography<43.0.0,>=3.1.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading cryptography-42.0.8-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading pyOpenSSL-24.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyjwt<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pytz (from snowflake-connector-python[pandas])\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging (from snowflake-connector-python[pandas])\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from snowflake-connector-python[pandas])\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from snowflake-connector-python[pandas])\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from snowflake-connector-python[pandas])\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python[pandas])\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting platformdirs<5.0.0,>=2.6.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tomlkit (from snowflake-connector-python[pandas])\n",
      "  Downloading tomlkit-0.13.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Downloading urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m219.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow (from snowflake-connector-python[pandas])\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "INFO: pip is looking at multiple versions of fosforml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fosforml\n",
      "  Downloading fosforml-1.1.5-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading fosforml-1.1.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading fosforml-1.0.9-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading fosforml-1.0.8-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of fosforml to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading fosforml-1.0.7-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.5-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading fosforml-1.0.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading fosforml-1.0.2-py3-none-any.whl.metadata (878 bytes)\n",
      "  Downloading fosforml-1.0.1-py3-none-any.whl.metadata (1.5 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading fosforml-1.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting requests-toolbelt==0.9.1 (from fosforml)\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting shutils==0.1.0 (from fosforml)\n",
      "  Downloading shutils-0.1.0.tar.gz (2.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting mosaic-utils (from fosforml)\n",
      "  Downloading mosaic_utils-1.0.2-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m221.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting configparser (from shutils==0.1.0->fosforml)\n",
      "  Downloading configparser-7.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pymysql (from shutils==0.1.0->fosforml)\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m240.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting six>=1.5 (from python-dateutil)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pycparser (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas])\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading snowflake_snowpark_python-1.9.0-py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fosforio-1.0.2-py3-none-any.whl (20 kB)\n",
      "Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m277.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fosforml-1.0.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m204.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m332.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m223.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m293.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m270.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m240.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m265.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m303.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m305.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m248.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading holidays-0.53-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m334.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Faker-26.0.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m300.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m190.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m296.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.16.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.7/444.7 kB\u001b[0m \u001b[31m314.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m295.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 kB\u001b[0m \u001b[31m308.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-42.0.8-cp37-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m315.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m256.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m206.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m305.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m319.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m312.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m227.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m277.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m329.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m230.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m199.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-71.1.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m277.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading snowflake_connector_python-3.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m330.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m304.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mosaic_utils-1.0.2-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m156.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m239.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m275.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m273.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.0-py3-none-any.whl (37 kB)\n",
      "Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m219.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading configparser-7.0.0-py3-none-any.whl (16 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m288.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m222.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: shutils\n",
      "  Building wheel for shutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shutils: filename=shutils-0.1.0-py3-none-any.whl size=3274 sha256=caab705e2bfd1bfc3bef3a389072b778d7d56538eabc3fe3197ea9c20b65632e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nh3c0uwx/wheels/c7/06/1a/4df9f03d511efd19a10f2086f67c38cf14757b555f4f24bd6e\n",
      "Successfully built shutils\n",
      "Installing collected packages: sortedcontainers, pytz, asn1crypto, zipp, wheel, urllib3, tzdata, typing-extensions, tqdm, tomlkit, threadpoolctl, six, setuptools, pyyaml, pyparsing, pymysql, pyjwt, pycparser, platformdirs, pillow, packaging, nvidia-nccl-cu12, numpy, kiwisolver, joblib, idna, fonttools, filelock, cycler, configparser, cloudpickle, charset-normalizer, certifi, shutils, scipy, requests, python-dateutil, pyarrow, importlib-resources, contourpy, cffi, xgboost, scikit-learn, requests-toolbelt, pandas, matplotlib, holidays, faker, cryptography, seaborn, pyOpenSSL, mosaic-utils, fosforio, snowflake-connector-python, fosforml, snowflake-snowpark-python\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlflow 2.10.0 requires packaging<24, but you have packaging 24.1 which is incompatible.\n",
      "mlflow 2.10.0 requires pyarrow<16,>=4.0.0, but you have pyarrow 17.0.0 which is incompatible.\n",
      "mlflow 2.10.0 requires pytz<2024, but you have pytz 2024.1 which is incompatible.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.0a1 which is incompatible.\n",
      "jupyterlab-server 2.25.4 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.7.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.3.3 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires itsdangerous==2.0.1, but you have itsdangerous 2.2.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Jinja2==3.0.3, but you have jinja2 3.1.4 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.7.5 which is incompatible.\n",
      "openapi-schema-validator 0.6.2 requires jsonschema<5.0.0,>=4.19.1, but you have jsonschema 3.2.0 which is incompatible.\n",
      "openapi-spec-validator 0.7.1 requires jsonschema<5.0.0,>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires absl-py<2,>=0.15, but you have absl-py 2.1.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires cryptography<39.0.0,>=3.1.0, but you have cryptography 42.0.8 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires packaging<24,>=20.9, but you have packaging 24.1 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires pandas<2,>=1.0.0, but you have pandas 2.0.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires xgboost<2,>=1.7.3, but you have xgboost 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asn1crypto-1.5.1 certifi-2024.7.4 cffi-1.16.0 charset-normalizer-3.3.2 cloudpickle-1.6.0 configparser-7.0.0 contourpy-1.1.1 cryptography-42.0.8 cycler-0.12.1 faker-26.0.0 filelock-3.15.4 fonttools-4.53.1 fosforio-1.0.2 fosforml-1.0.0 holidays-0.53 idna-3.7 importlib-resources-6.4.0 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.7.5 mosaic-utils-1.0.2 numpy-1.24.4 nvidia-nccl-cu12-2.22.3 packaging-24.1 pandas-2.0.0 pillow-10.4.0 platformdirs-4.2.2 pyOpenSSL-24.2.1 pyarrow-17.0.0 pycparser-2.22 pyjwt-2.8.0 pymysql-1.1.1 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0 requests-2.32.3 requests-toolbelt-0.9.1 scikit-learn-1.2.1 scipy-1.10.1 seaborn-0.13.2 setuptools-71.1.0 shutils-0.1.0 six-1.16.0 snowflake-connector-python-3.12.0 snowflake-snowpark-python-1.9.0 sortedcontainers-2.4.0 threadpoolctl-3.5.0 tomlkit-0.13.0 tqdm-4.66.4 typing-extensions-4.12.2 tzdata-2024.1 urllib3-1.26.15 wheel-0.43.0 xgboost-2.1.0 zipp-3.19.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers-2.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel-0.43.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-1.26.15.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm-4.66.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit-0.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl-3.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools-71.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyYAML-6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing-3.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pymysql already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyMySQL-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/jwt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyJWT-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser-2.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs-4.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow-10.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/nvidia already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/nvidia_nccl_cu12-2.22.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.24.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver-1.4.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib-1.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fontTools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fonttools-4.53.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock-3.15.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler-0.12.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/backports already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/configparser-7.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle-1.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.7.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/shutils already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/shutils-0.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy-1.10.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.32.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scripts already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/benchmarks already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow-17.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/examples already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cmake_modules already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources-6.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_cffi_backend.cpython-38-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost-2.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn-1.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_toolbelt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_toolbelt-0.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.7.5-py3.8-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.7.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/holidays already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/holidays-0.53.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/faker already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/Faker-26.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography-42.0.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/seaborn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/seaborn-0.13.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/OpenSSL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyOpenSSL-24.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mosaic_utils already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mosaic_utils-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforio-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_connector_python-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforml-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0-py3.11-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlflow 2.10.0 requires packaging<24, but you have packaging 24.1 which is incompatible.\n",
      "mlflow 2.10.0 requires pytz<2024, but you have pytz 2024.1 which is incompatible.\n",
      "fosforml 1.0.0 requires cloudpickle==1.6.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "fosforml 1.0.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "fosforml 1.0.0 requires urllib3==1.26.15, but you have urllib3 1.26.19 which is incompatible.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.0a1 which is incompatible.\n",
      "jupyterlab-server 2.25.4 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.7.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.3.3 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires itsdangerous==2.0.1, but you have itsdangerous 2.2.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Jinja2==3.0.3, but you have jinja2 3.1.4 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.7.5 which is incompatible.\n",
      "openapi-schema-validator 0.6.2 requires jsonschema<5.0.0,>=4.19.1, but you have jsonschema 3.2.0 which is incompatible.\n",
      "openapi-spec-validator 0.7.1 requires jsonschema<5.0.0,>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires absl-py<2,>=0.15, but you have absl-py 2.1.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires cryptography<39.0.0,>=3.1.0, but you have cryptography 42.0.8 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires packaging<24,>=20.9, but you have packaging 24.1 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires pandas<2,>=1.0.0, but you have pandas 2.0.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires xgboost<2,>=1.7.3, but you have xgboost 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: urllib3 1.26.15\n",
      "Uninstalling urllib3-1.26.15:\n",
      "  Successfully uninstalled urllib3-1.26.15\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting urllib3==1.26.15\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforml 1.0.0 requires cloudpickle==1.6.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "fosforml 1.0.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "snowflake-snowpark-python 1.9.0 requires cloudpickle<=2.0.0,>=1.6.0; python_version < \"3.11\", but you have cloudpickle 2.2.1 which is incompatible.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.11.0 which is incompatible.\n",
      "jupyterlab-server 2.25.4 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.7.5 which is incompatible.\n",
      "openapi-spec-validator 0.7.1 requires jsonschema<5.0.0,>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires absl-py<2,>=0.15, but you have absl-py 2.1.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires cryptography<39.0.0,>=3.1.0, but you have cryptography 42.0.8 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires pandas<2,>=1.0.0, but you have pandas 2.0.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires xgboost<2,>=1.7.3, but you have xgboost 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting absl-py>=1.0.0 (from tensorflow[and-cuda])\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow[and-cuda])\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow[and-cuda])\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow[and-cuda])\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow[and-cuda])\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow[and-cuda])\n",
      "  Downloading grpcio-1.65.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow[and-cuda])\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow[and-cuda])\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting libclang>=13.0.0 (from tensorflow[and-cuda])\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow[and-cuda])\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow[and-cuda])\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting packaging (from tensorflow[and-cuda])\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow[and-cuda])\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting setuptools (from tensorflow[and-cuda])\n",
      "  Downloading setuptools-71.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow[and-cuda])\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow[and-cuda])\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow[and-cuda])\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow[and-cuda])\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow[and-cuda])\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow[and-cuda])\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow[and-cuda])\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow[and-cuda])\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading importlib_metadata-8.2.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow[and-cuda])\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m223.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m189.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m336.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m158.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m253.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m327.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m153.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-71.1.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m169.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m327.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m166.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m249.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m233.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.6/479.6 MB\u001b[0m \u001b[31m175.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.5/195.5 kB\u001b[0m \u001b[31m297.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m277.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m242.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m181.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m310.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m241.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m279.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m287.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m236.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m303.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m291.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m301.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m268.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: libclang, flatbuffers, zipp, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, opt-einsum, importlib-metadata, h5py, google-pasta, astunparse, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sqlalchemy 2.0.30 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "mlflow 2.10.0 requires importlib-metadata!=4.7.0,<8,>=3.7.0, but you have importlib-metadata 8.2.0 which is incompatible.\n",
      "mlflow 2.10.0 requires packaging<24, but you have packaging 24.1 which is incompatible.\n",
      "fosforml 1.0.0 requires cloudpickle==1.6.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "fosforml 1.0.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "fosforml 1.0.0 requires urllib3==1.26.15, but you have urllib3 2.2.2 which is incompatible.\n",
      "mosaic-utils 1.0.2 requires scikit-learn==1.2.1; python_version >= \"3.8\", but you have scikit-learn 1.3.2 which is incompatible.\n",
      "snowflake-connector-python 3.12.0 requires urllib3<2.0.0,>=1.21.1; python_version < \"3.10\", but you have urllib3 2.2.2 which is incompatible.\n",
      "snowflake-snowpark-python 1.9.0 requires cloudpickle<=2.0.0,>=1.6.0; python_version < \"3.11\", but you have cloudpickle 2.2.1 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.0a1 which is incompatible.\n",
      "jupyterlab-server 2.25.4 requires jsonschema>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.7.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.3.3 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires itsdangerous==2.0.1, but you have itsdangerous 2.2.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Jinja2==3.0.3, but you have jinja2 3.1.4 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.7.5 which is incompatible.\n",
      "openapi-schema-validator 0.6.2 requires jsonschema<5.0.0,>=4.19.1, but you have jsonschema 3.2.0 which is incompatible.\n",
      "openapi-spec-validator 0.7.1 requires jsonschema<5.0.0,>=4.18.0, but you have jsonschema 3.2.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires absl-py<2,>=0.15, but you have absl-py 2.1.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires cryptography<39.0.0,>=3.1.0, but you have cryptography 42.0.8 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires packaging<24,>=20.9, but you have packaging 24.1 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires pandas<2,>=1.0.0, but you have pandas 2.0.0 which is incompatible.\n",
      "snowflake-ml-python 1.0.1 requires xgboost<2,>=1.7.3, but you have xgboost 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.4.0 certifi-2024.7.4 charset-normalizer-3.3.2 flatbuffers-24.3.25 gast-0.4.0 google-auth-2.32.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.65.1 h5py-3.11.0 idna-3.7 importlib-metadata-8.2.0 keras-2.13.1 libclang-18.1.1 markdown-3.6 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-24.1 protobuf-4.25.4 pyasn1-0.6.0 pyasn1-modules-0.4.0 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9 setuptools-71.1.0 six-1.16.0 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 typing-extensions-4.5.0 urllib3-2.2.2 werkzeug-3.0.3 wheel-0.43.0 wrapt-1.16.0 zipp-3.19.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/libclang-18.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/clang already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/flatbuffers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/flatbuffers-24.3.25.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wrapt-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wrapt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel-0.43.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions-4.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/termcolor already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/termcolor-2.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorflow_io_gcs_filesystem already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorflow_io_gcs_filesystem-0.34.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorflow_estimator already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorflow_estimator-2.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorboard_data_server already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorboard_data_server-0.7.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools-71.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyasn1 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyasn1-0.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/google already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/protobuf-4.25.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/oauthlib-3.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.24.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/markupsafe already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/MarkupSafe-2.1.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/keras already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/keras-2.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/grpc already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/grpcio-1.65.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/gast already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/gast-0.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.7.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cachetools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cachetools-5.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/absl already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/absl_py-2.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/werkzeug already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/werkzeug-3.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/rsa already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/rsa-4.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.32.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyasn1_modules already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyasn1_modules-0.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/opt_einsum already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/opt_einsum-3.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_metadata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_metadata-8.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/h5py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/h5py-3.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/h5py.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pasta already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/google_pasta-0.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/astunparse already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/astunparse-1.6.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests_oauthlib-2.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/markdown already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/Markdown-3.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/google_auth-2.32.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/google_auth_oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/google_auth_oauthlib-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorboard already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorboard-2.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorflow-2.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tensorflow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio fosforml numpy pandas matplotlib scikit-learn xgboost seaborn python-dateutil tqdm holidays faker\n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fed65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection manager service url initialised to http://fdc-project-manager:80/project-manager\n",
      "If you need to update its value then update the variable CONNECTION_MANAGER_BASE_URL in os env.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-hy02bvxn because the default path (/home/mosaic-ai/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "from time import sleep\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47834e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fec536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred in getting snowflake connection: 'connectionSources'\n",
      "Reading dataframe from snowflake native connector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>NOC</th>\n",
       "      <th>GAMES</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>CITY</th>\n",
       "      <th>SPORT</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>MEDAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>185</td>\n",
       "      <td>82</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271111</th>\n",
       "      <td>135569</td>\n",
       "      <td>Andrzej ya</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>Poland-1</td>\n",
       "      <td>POL</td>\n",
       "      <td>1976 Winter</td>\n",
       "      <td>1976</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Innsbruck</td>\n",
       "      <td>Luge</td>\n",
       "      <td>Luge Mixed (Men)'s Doubles</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271112</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>59</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Individual</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271113</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>59</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Team</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271114</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>185</td>\n",
       "      <td>96</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>1998 Winter</td>\n",
       "      <td>1998</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Nagano</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271115</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>185</td>\n",
       "      <td>96</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2002 Winter</td>\n",
       "      <td>2002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271116 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                      NAME SEX AGE HEIGHT WEIGHT  \\\n",
       "0            1                 A Dijiang   M  24    180     80   \n",
       "1            2                  A Lamusi   M  23    170     60   \n",
       "2            3       Gunnar Nielsen Aaby   M  24     NA     NA   \n",
       "3            4      Edgar Lindenau Aabye   M  34     NA     NA   \n",
       "4            5  Christine Jacoba Aaftink   F  21    185     82   \n",
       "...        ...                       ...  ..  ..    ...    ...   \n",
       "271111  135569                Andrzej ya   M  29    179     89   \n",
       "271112  135570                  Piotr ya   M  27    176     59   \n",
       "271113  135570                  Piotr ya   M  27    176     59   \n",
       "271114  135571        Tomasz Ireneusz ya   M  30    185     96   \n",
       "271115  135571        Tomasz Ireneusz ya   M  34    185     96   \n",
       "\n",
       "                  TEAM  NOC        GAMES  YEAR  SEASON            CITY  \\\n",
       "0                China  CHN  1992 Summer  1992  Summer       Barcelona   \n",
       "1                China  CHN  2012 Summer  2012  Summer          London   \n",
       "2              Denmark  DEN  1920 Summer  1920  Summer       Antwerpen   \n",
       "3       Denmark/Sweden  DEN  1900 Summer  1900  Summer           Paris   \n",
       "4          Netherlands  NED  1988 Winter  1988  Winter         Calgary   \n",
       "...                ...  ...          ...   ...     ...             ...   \n",
       "271111        Poland-1  POL  1976 Winter  1976  Winter       Innsbruck   \n",
       "271112          Poland  POL  2014 Winter  2014  Winter           Sochi   \n",
       "271113          Poland  POL  2014 Winter  2014  Winter           Sochi   \n",
       "271114          Poland  POL  1998 Winter  1998  Winter          Nagano   \n",
       "271115          Poland  POL  2002 Winter  2002  Winter  Salt Lake City   \n",
       "\n",
       "                SPORT                                     EVENT MEDAL  \n",
       "0          Basketball               Basketball Men's Basketball    NA  \n",
       "1                Judo              Judo Men's Extra-Lightweight    NA  \n",
       "2            Football                   Football Men's Football    NA  \n",
       "3          Tug-Of-War               Tug-Of-War Men's Tug-Of-War  Gold  \n",
       "4       Speed Skating          Speed Skating Women's 500 metres    NA  \n",
       "...               ...                                       ...   ...  \n",
       "271111           Luge                Luge Mixed (Men)'s Doubles    NA  \n",
       "271112    Ski Jumping  Ski Jumping Men's Large Hill, Individual    NA  \n",
       "271113    Ski Jumping        Ski Jumping Men's Large Hill, Team    NA  \n",
       "271114      Bobsleigh                      Bobsleigh Men's Four    NA  \n",
       "271115      Bobsleigh                      Bobsleigh Men's Four    NA  \n",
       "\n",
       "[271116 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Data\n",
    "\n",
    "snowflake.get_connection(connection_name=\"ME_OLYMPICS_CNX\")\n",
    "data = get_dataframe(\"ATHLETE_EVENTS\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa82db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataframe from snowflake native connector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>NOC</th>\n",
       "      <th>GAMES</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>CITY</th>\n",
       "      <th>SPORT</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>MEDAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>185</td>\n",
       "      <td>82</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271111</th>\n",
       "      <td>135569</td>\n",
       "      <td>Andrzej ya</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>179</td>\n",
       "      <td>89</td>\n",
       "      <td>Poland-1</td>\n",
       "      <td>POL</td>\n",
       "      <td>1976 Winter</td>\n",
       "      <td>1976</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Innsbruck</td>\n",
       "      <td>Luge</td>\n",
       "      <td>Luge Mixed (Men)'s Doubles</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271112</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>59</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Individual</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271113</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>59</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Team</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271114</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>185</td>\n",
       "      <td>96</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>1998 Winter</td>\n",
       "      <td>1998</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Nagano</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271115</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>185</td>\n",
       "      <td>96</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2002 Winter</td>\n",
       "      <td>2002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271116 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                      NAME SEX AGE HEIGHT WEIGHT  \\\n",
       "0            1                 A Dijiang   M  24    180     80   \n",
       "1            2                  A Lamusi   M  23    170     60   \n",
       "2            3       Gunnar Nielsen Aaby   M  24     NA     NA   \n",
       "3            4      Edgar Lindenau Aabye   M  34     NA     NA   \n",
       "4            5  Christine Jacoba Aaftink   F  21    185     82   \n",
       "...        ...                       ...  ..  ..    ...    ...   \n",
       "271111  135569                Andrzej ya   M  29    179     89   \n",
       "271112  135570                  Piotr ya   M  27    176     59   \n",
       "271113  135570                  Piotr ya   M  27    176     59   \n",
       "271114  135571        Tomasz Ireneusz ya   M  30    185     96   \n",
       "271115  135571        Tomasz Ireneusz ya   M  34    185     96   \n",
       "\n",
       "                  TEAM  NOC        GAMES  YEAR  SEASON            CITY  \\\n",
       "0                China  CHN  1992 Summer  1992  Summer       Barcelona   \n",
       "1                China  CHN  2012 Summer  2012  Summer          London   \n",
       "2              Denmark  DEN  1920 Summer  1920  Summer       Antwerpen   \n",
       "3       Denmark/Sweden  DEN  1900 Summer  1900  Summer           Paris   \n",
       "4          Netherlands  NED  1988 Winter  1988  Winter         Calgary   \n",
       "...                ...  ...          ...   ...     ...             ...   \n",
       "271111        Poland-1  POL  1976 Winter  1976  Winter       Innsbruck   \n",
       "271112          Poland  POL  2014 Winter  2014  Winter           Sochi   \n",
       "271113          Poland  POL  2014 Winter  2014  Winter           Sochi   \n",
       "271114          Poland  POL  1998 Winter  1998  Winter          Nagano   \n",
       "271115          Poland  POL  2002 Winter  2002  Winter  Salt Lake City   \n",
       "\n",
       "                SPORT                                     EVENT MEDAL  \n",
       "0          Basketball               Basketball Men's Basketball    NA  \n",
       "1                Judo              Judo Men's Extra-Lightweight    NA  \n",
       "2            Football                   Football Men's Football    NA  \n",
       "3          Tug-Of-War               Tug-Of-War Men's Tug-Of-War  Gold  \n",
       "4       Speed Skating          Speed Skating Women's 500 metres    NA  \n",
       "...               ...                                       ...   ...  \n",
       "271111           Luge                Luge Mixed (Men)'s Doubles    NA  \n",
       "271112    Ski Jumping  Ski Jumping Men's Large Hill, Individual    NA  \n",
       "271113    Ski Jumping        Ski Jumping Men's Large Hill, Team    NA  \n",
       "271114      Bobsleigh                      Bobsleigh Men's Four    NA  \n",
       "271115      Bobsleigh                      Bobsleigh Men's Four    NA  \n",
       "\n",
       "[271116 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bkp = get_dataframe(\"ATHLETE_EVENTS\")\n",
    "data_bkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91114a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23': 21875,\n",
       " '24': 21720,\n",
       " '22': 20814,\n",
       " '25': 19707,\n",
       " '21': 19164,\n",
       " '26': 17675,\n",
       " '27': 16025,\n",
       " '20': 15258,\n",
       " '28': 14043,\n",
       " '19': 11643,\n",
       " '29': 11463,\n",
       " '30': 9488,\n",
       " 'NA': 9474,\n",
       " '18': 8152,\n",
       " '31': 7559,\n",
       " '32': 6246,\n",
       " '17': 5376,\n",
       " '33': 4800,\n",
       " '34': 3985,\n",
       " '16': 3852,\n",
       " '35': 3133,\n",
       " '36': 2503,\n",
       " '15': 2203,\n",
       " '37': 1953,\n",
       " '38': 1612,\n",
       " '39': 1405,\n",
       " '40': 1210,\n",
       " '41': 953,\n",
       " '42': 866,\n",
       " '14': 837,\n",
       " '43': 793,\n",
       " '44': 683,\n",
       " '45': 584,\n",
       " '46': 429,\n",
       " '47': 408,\n",
       " '48': 407,\n",
       " '49': 362,\n",
       " '50': 278,\n",
       " '52': 244,\n",
       " '53': 200,\n",
       " '51': 199,\n",
       " '13': 187,\n",
       " '54': 162,\n",
       " '56': 131,\n",
       " '55': 104,\n",
       " '60': 88,\n",
       " '59': 87,\n",
       " '58': 84,\n",
       " '65': 84,\n",
       " '57': 69,\n",
       " '61': 68,\n",
       " '62': 62,\n",
       " '69': 60,\n",
       " '63': 56,\n",
       " '12': 39,\n",
       " '71': 33,\n",
       " '66': 31,\n",
       " '64': 30,\n",
       " '70': 28,\n",
       " '67': 25,\n",
       " '68': 25,\n",
       " '72': 24,\n",
       " '11': 13,\n",
       " '74': 12,\n",
       " '73': 8,\n",
       " '76': 7,\n",
       " '75': 4,\n",
       " '88': 3,\n",
       " '80': 3,\n",
       " '81': 2,\n",
       " '77': 2,\n",
       " '84': 1,\n",
       " '96': 1,\n",
       " '10': 1,\n",
       " '97': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AGE'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1eb372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271116 entries, 0 to 271115\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   ID      271116 non-null  int32 \n",
      " 1   NAME    271116 non-null  object\n",
      " 2   SEX     271116 non-null  object\n",
      " 3   AGE     271116 non-null  object\n",
      " 4   HEIGHT  271116 non-null  object\n",
      " 5   WEIGHT  271116 non-null  object\n",
      " 6   TEAM    271116 non-null  object\n",
      " 7   NOC     271116 non-null  object\n",
      " 8   GAMES   271116 non-null  object\n",
      " 9   YEAR    271116 non-null  int16 \n",
      " 10  SEASON  271116 non-null  object\n",
      " 11  CITY    271116 non-null  object\n",
      " 12  SPORT   271116 non-null  object\n",
      " 13  EVENT   271116 non-null  object\n",
      " 14  MEDAL   271116 non-null  object\n",
      "dtypes: int16(1), int32(1), object(13)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7067e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AGE'][data['AGE']!='NA'].astype(int).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf8592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['WEIGHT'][data['WEIGHT']!='NA'].astype(float).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e03711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['HEIGHT'][data['HEIGHT']!='NA'].astype(int).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "055588ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         24\n",
       "1         23\n",
       "2         24\n",
       "3         34\n",
       "4         21\n",
       "          ..\n",
       "271111    29\n",
       "271112    27\n",
       "271113    27\n",
       "271114    30\n",
       "271115    34\n",
       "Name: AGE, Length: 271116, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AGE'].replace('NA',int(data['AGE'][data['AGE']!='NA'].astype(int).median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554ce4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AGE'] = data['AGE'].replace('NA',str(int(data['AGE'][data['AGE']!='NA'].astype(int).median()))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccace873",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['HEIGHT'] = data['HEIGHT'].replace('NA',str(int(data['HEIGHT'][data['HEIGHT']!='NA'].astype(int).median()))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b1b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['WEIGHT'] = data['WEIGHT'].replace('NA',str(float(data['WEIGHT'][data['WEIGHT']!='NA'].astype(float).median()))).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d0a0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{70.0: 72500,\n",
       " 60.0: 7994,\n",
       " 75.0: 7810,\n",
       " 68.0: 7284,\n",
       " 65.0: 7236,\n",
       " 72.0: 6252,\n",
       " 80.0: 6214,\n",
       " 73.0: 5937,\n",
       " 63.0: 5869,\n",
       " 64.0: 5764,\n",
       " 62.0: 5611,\n",
       " 67.0: 5263,\n",
       " 58.0: 5243,\n",
       " 78.0: 4995,\n",
       " 74.0: 4809,\n",
       " 66.0: 4764,\n",
       " 57.0: 4640,\n",
       " 82.0: 4186,\n",
       " 76.0: 4109,\n",
       " 55.0: 4106,\n",
       " 77.0: 4035,\n",
       " 56.0: 4029,\n",
       " 69.0: 4027,\n",
       " 59.0: 4012,\n",
       " 85.0: 3909,\n",
       " 61.0: 3817,\n",
       " 71.0: 3637,\n",
       " 54.0: 3507,\n",
       " 52.0: 3450,\n",
       " 90.0: 3371,\n",
       " 79.0: 3146,\n",
       " 84.0: 2945,\n",
       " 83.0: 2925,\n",
       " 50.0: 2587,\n",
       " 81.0: 2557,\n",
       " 86.0: 2536,\n",
       " 53.0: 2386,\n",
       " 88.0: 2142,\n",
       " 48.0: 1965,\n",
       " 87.0: 1876,\n",
       " 95.0: 1842,\n",
       " 51.0: 1839,\n",
       " 100.0: 1544,\n",
       " 92.0: 1473,\n",
       " 89.0: 1438,\n",
       " 93.0: 1409,\n",
       " 91.0: 1324,\n",
       " 49.0: 1110,\n",
       " 47.0: 1039,\n",
       " 94.0: 990,\n",
       " 98.0: 892,\n",
       " 96.0: 859,\n",
       " 46.0: 777,\n",
       " 45.0: 746,\n",
       " 97.0: 684,\n",
       " 105.0: 602,\n",
       " 43.0: 521,\n",
       " 102.0: 504,\n",
       " 44.0: 442,\n",
       " 110.0: 428,\n",
       " 120.0: 395,\n",
       " 40.0: 372,\n",
       " 99.0: 370,\n",
       " 42.0: 344,\n",
       " 104.0: 314,\n",
       " 115.0: 292,\n",
       " 41.0: 259,\n",
       " 103.0: 249,\n",
       " 130.0: 203,\n",
       " 125.0: 199,\n",
       " 39.0: 196,\n",
       " 38.0: 195,\n",
       " 107.0: 187,\n",
       " 108.0: 174,\n",
       " 106.0: 174,\n",
       " 37.0: 173,\n",
       " 101.0: 166,\n",
       " 36.0: 137,\n",
       " 112.0: 125,\n",
       " 109.0: 123,\n",
       " 118.0: 107,\n",
       " 114.0: 103,\n",
       " 35.0: 92,\n",
       " 111.0: 77,\n",
       " 34.0: 73,\n",
       " 113.0: 72,\n",
       " 63.5: 71,\n",
       " 116.0: 59,\n",
       " 128.0: 57,\n",
       " 69.5: 56,\n",
       " 140.0: 52,\n",
       " 67.5: 51,\n",
       " 33.0: 51,\n",
       " 55.5: 48,\n",
       " 117.0: 44,\n",
       " 135.0: 43,\n",
       " 30.0: 42,\n",
       " 32.0: 41,\n",
       " 59.5: 41,\n",
       " 127.0: 41,\n",
       " 76.5: 40,\n",
       " 123.0: 40,\n",
       " 122.0: 38,\n",
       " 77.5: 34,\n",
       " 126.0: 34,\n",
       " 68.5: 34,\n",
       " 70.5: 34,\n",
       " 81.5: 31,\n",
       " 132.0: 30,\n",
       " 52.5: 28,\n",
       " 65.5: 28,\n",
       " 73.5: 27,\n",
       " 124.0: 26,\n",
       " 74.5: 26,\n",
       " 78.5: 25,\n",
       " 54.5: 25,\n",
       " 79.5: 25,\n",
       " 119.0: 24,\n",
       " 75.5: 23,\n",
       " 31.0: 23,\n",
       " 66.5: 22,\n",
       " 145.0: 21,\n",
       " 136.0: 20,\n",
       " 83.5: 20,\n",
       " 121.0: 19,\n",
       " 72.5: 19,\n",
       " 60.5: 18,\n",
       " 150.0: 18,\n",
       " 87.5: 17,\n",
       " 131.0: 17,\n",
       " 82.5: 17,\n",
       " 64.5: 16,\n",
       " 61.5: 16,\n",
       " 141.0: 16,\n",
       " 86.5: 15,\n",
       " 88.5: 15,\n",
       " 134.0: 15,\n",
       " 129.0: 14,\n",
       " 146.0: 14,\n",
       " 28.0: 14,\n",
       " 148.0: 14,\n",
       " 97.5: 13,\n",
       " 133.0: 13,\n",
       " 138.0: 13,\n",
       " 139.0: 12,\n",
       " 57.5: 12,\n",
       " 89.5: 12,\n",
       " 160.0: 12,\n",
       " 71.5: 12,\n",
       " 62.5: 12,\n",
       " 137.0: 11,\n",
       " 85.5: 10,\n",
       " 102.5: 9,\n",
       " 144.0: 9,\n",
       " 91.5: 9,\n",
       " 56.5: 8,\n",
       " 142.0: 8,\n",
       " 84.5: 7,\n",
       " 163.0: 7,\n",
       " 92.5: 7,\n",
       " 155.0: 6,\n",
       " 53.5: 6,\n",
       " 147.0: 6,\n",
       " 161.0: 6,\n",
       " 103.5: 6,\n",
       " 25.0: 6,\n",
       " 80.5: 6,\n",
       " 96.5: 5,\n",
       " 170.0: 5,\n",
       " 101.5: 5,\n",
       " 112.5: 5,\n",
       " 154.0: 5,\n",
       " 156.0: 5,\n",
       " 98.5: 5,\n",
       " 165.0: 5,\n",
       " 143.0: 5,\n",
       " 117.5: 5,\n",
       " 105.5: 4,\n",
       " 106.5: 4,\n",
       " 90.5: 4,\n",
       " 93.5: 4,\n",
       " 108.5: 4,\n",
       " 138.5: 3,\n",
       " 122.5: 3,\n",
       " 58.5: 3,\n",
       " 131.5: 3,\n",
       " 129.5: 3,\n",
       " 123.5: 3,\n",
       " 158.0: 3,\n",
       " 135.5: 3,\n",
       " 100.5: 3,\n",
       " 77.3333333333333: 3,\n",
       " 74.6666666666667: 3,\n",
       " 49.5: 3,\n",
       " 107.5: 2,\n",
       " 133.5: 2,\n",
       " 137.5: 2,\n",
       " 182.0: 2,\n",
       " 104.5: 2,\n",
       " 95.5: 2,\n",
       " 118.5: 2,\n",
       " 51.5: 2,\n",
       " 116.5: 2,\n",
       " 146.5: 2,\n",
       " 214.0: 2,\n",
       " 109.5: 2,\n",
       " 127.5: 2,\n",
       " 130.5: 2,\n",
       " 121.5: 2,\n",
       " 176.5: 2,\n",
       " 152.0: 2,\n",
       " 167.0: 2,\n",
       " 175.0: 1,\n",
       " 151.0: 1,\n",
       " 178.0: 1,\n",
       " 190.0: 1,\n",
       " 180.0: 1,\n",
       " 149.0: 1,\n",
       " 48.5: 1,\n",
       " 198.0: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['WEIGHT'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "990bbf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271116 entries, 0 to 271115\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   ID      271116 non-null  int32  \n",
      " 1   NAME    271116 non-null  object \n",
      " 2   SEX     271116 non-null  object \n",
      " 3   AGE     271116 non-null  int64  \n",
      " 4   HEIGHT  271116 non-null  int64  \n",
      " 5   WEIGHT  271116 non-null  float64\n",
      " 6   TEAM    271116 non-null  object \n",
      " 7   NOC     271116 non-null  object \n",
      " 8   GAMES   271116 non-null  object \n",
      " 9   YEAR    271116 non-null  int16  \n",
      " 10  SEASON  271116 non-null  object \n",
      " 11  CITY    271116 non-null  object \n",
      " 12  SPORT   271116 non-null  object \n",
      " 13  EVENT   271116 non-null  object \n",
      " 14  MEDAL   271116 non-null  object \n",
      "dtypes: float64(1), int16(1), int32(1), int64(2), object(10)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70802783",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "272880b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271116 entries, 0 to 271115\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      271116 non-null  int32  \n",
      " 1   name    271116 non-null  object \n",
      " 2   sex     271116 non-null  object \n",
      " 3   age     271116 non-null  int64  \n",
      " 4   height  271116 non-null  int64  \n",
      " 5   weight  271116 non-null  float64\n",
      " 6   team    271116 non-null  object \n",
      " 7   noc     271116 non-null  object \n",
      " 8   games   271116 non-null  object \n",
      " 9   year    271116 non-null  int16  \n",
      " 10  season  271116 non-null  object \n",
      " 11  city    271116 non-null  object \n",
      " 12  sport   271116 non-null  object \n",
      " 13  event   271116 non-null  object \n",
      " 14  medal   271116 non-null  object \n",
      "dtypes: float64(1), int16(1), int32(1), int64(2), object(10)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.columns = data.columns.str.lower()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d0249",
   "metadata": {},
   "source": [
    "# CREATING LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f7cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medal'] = data['medal'].apply(lambda x: 1 if str(x) != 'nan' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "077c5841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "24    31194\n",
       "23    21875\n",
       "22    20814\n",
       "25    19707\n",
       "21    19164\n",
       "      ...  \n",
       "77        2\n",
       "84        1\n",
       "10        1\n",
       "96        1\n",
       "97        1\n",
       "Name: count, Length: 74, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17b996",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e305f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         int32\n",
      "name      object\n",
      "sex       object\n",
      "age        int64\n",
      "height     int64\n",
      "weight     int64\n",
      "team      object\n",
      "noc       object\n",
      "games     object\n",
      "year       int16\n",
      "season    object\n",
      "city      object\n",
      "sport     object\n",
      "event     object\n",
      "medal      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# converting datatypes\n",
    "data = data.astype({'age': int, 'height': int, 'weight': int})\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c34c7fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id', 'name', 'games'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgames\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['id', 'name', 'games'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data = data.drop(['id', 'name', 'games'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b0ac596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex       0.0\n",
       "age       0.0\n",
       "height    0.0\n",
       "weight    0.0\n",
       "team      0.0\n",
       "noc       0.0\n",
       "year      0.0\n",
       "season    0.0\n",
       "city      0.0\n",
       "sport     0.0\n",
       "event     0.0\n",
       "medal     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "993ab0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total missing values:\", data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "457440b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1896      380\n",
       "1904     1301\n",
       "1906     1733\n",
       "1900     1936\n",
       "1908     3101\n",
       "1994     3160\n",
       "1932     3321\n",
       "1998     3605\n",
       "1912     4040\n",
       "2002     4109\n",
       "1920     4292\n",
       "2006     4382\n",
       "2010     4402\n",
       "2014     4891\n",
       "1928     5574\n",
       "1924     5693\n",
       "1956     6434\n",
       "1936     7401\n",
       "1948     7480\n",
       "1980     8937\n",
       "1960     9235\n",
       "1952     9358\n",
       "1964     9480\n",
       "1968    10479\n",
       "1976    10502\n",
       "1984    11588\n",
       "1972    11959\n",
       "2012    12920\n",
       "2004    13443\n",
       "2008    13602\n",
       "2016    13688\n",
       "1996    13780\n",
       "2000    13821\n",
       "1988    14676\n",
       "1992    16413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['year'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10e35673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "Summer    222552\n",
       "Winter     48564\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e76dcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[data['season'] == 'Summer'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95c7604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "Summer    222552\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea0806de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158148 entries, 0 to 158147\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   level_0  158148 non-null  int64 \n",
      " 1   index    158148 non-null  int64 \n",
      " 2   sex      158148 non-null  object\n",
      " 3   age      158148 non-null  int64 \n",
      " 4   height   158148 non-null  int64 \n",
      " 5   weight   158148 non-null  int64 \n",
      " 6   team     158148 non-null  object\n",
      " 7   noc      158148 non-null  object\n",
      " 8   year     158148 non-null  int16 \n",
      " 9   season   158148 non-null  object\n",
      " 10  city     158148 non-null  object\n",
      " 11  sport    158148 non-null  object\n",
      " 12  event    158148 non-null  object\n",
      " 13  medal    158148 non-null  int64 \n",
      "dtypes: int16(1), int64(6), object(7)\n",
      "memory usage: 16.0+ MB\n"
     ]
    }
   ],
   "source": [
    "f_data = filtered_data[filtered_data['year'] > 1960].reset_index()\n",
    "f_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9bb3ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2000    13821\n",
       "1996    13780\n",
       "2016    13688\n",
       "2008    13602\n",
       "2004    13443\n",
       "1992    12977\n",
       "2012    12920\n",
       "1988    12037\n",
       "1972    10304\n",
       "1984     9454\n",
       "1976     8641\n",
       "1968     8588\n",
       "1964     7702\n",
       "1980     7191\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1608414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>sport</th>\n",
       "      <th>medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>China</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>China</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>31</td>\n",
       "      <td>172</td>\n",
       "      <td>70</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2000</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>159</td>\n",
       "      <td>55</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1996</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Sailing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>159</td>\n",
       "      <td>55</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2000</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sailing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158143</th>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>168</td>\n",
       "      <td>76</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2004</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Athina</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158144</th>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>175</td>\n",
       "      <td>75</td>\n",
       "      <td>United States</td>\n",
       "      <td>1972</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Football</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158145</th>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>183</td>\n",
       "      <td>72</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2000</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Rowing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158146</th>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>183</td>\n",
       "      <td>72</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2004</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Athina</td>\n",
       "      <td>Rowing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158147</th>\n",
       "      <td>F</td>\n",
       "      <td>33</td>\n",
       "      <td>171</td>\n",
       "      <td>69</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>2016</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158148 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  age  height  weight           team  year  season            city  \\\n",
       "0        M   24     180      80          China  1992  Summer       Barcelona   \n",
       "1        M   23     170      60          China  2012  Summer          London   \n",
       "2        M   31     172      70        Finland  2000  Summer          Sydney   \n",
       "3        F   30     159      55        Finland  1996  Summer         Atlanta   \n",
       "4        F   34     159      55        Finland  2000  Summer          Sydney   \n",
       "...     ..  ...     ...     ...            ...   ...     ...             ...   \n",
       "158143   M   27     168      76      Argentina  2004  Summer          Athina   \n",
       "158144   M   21     175      75  United States  1972  Summer          Munich   \n",
       "158145   M   24     183      72         Russia  2000  Summer          Sydney   \n",
       "158146   M   28     183      72         Russia  2004  Summer          Athina   \n",
       "158147   F   33     171      69        Belarus  2016  Summer  Rio de Janeiro   \n",
       "\n",
       "             sport  medal  \n",
       "0       Basketball      1  \n",
       "1             Judo      1  \n",
       "2        Badminton      1  \n",
       "3          Sailing      1  \n",
       "4          Sailing      1  \n",
       "...            ...    ...  \n",
       "158143      Hockey      1  \n",
       "158144    Football      1  \n",
       "158145      Rowing      1  \n",
       "158146      Rowing      1  \n",
       "158147  Basketball      1  \n",
       "\n",
       "[158148 rows x 10 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ba138bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['event'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f_data \u001b[38;5;241m=\u001b[39m \u001b[43mf_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnoc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['event'] not found in axis\""
     ]
    }
   ],
   "source": [
    "f_data = f_data.drop(['event'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2e64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1042e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = f_data.drop(['noc', 'level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27041725",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data1 = f_data[f_data['sport'].map(f_data['sport'].value_counts()) > 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1bebec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport\n",
       "Athletics        26780\n",
       "Swimming         19377\n",
       "Gymnastics       16433\n",
       "Cycling           7494\n",
       "Rowing            7418\n",
       "Shooting          6939\n",
       "Fencing           5747\n",
       "Canoeing          5348\n",
       "Wrestling         4862\n",
       "Sailing           4749\n",
       "Football          4615\n",
       "Boxing            4380\n",
       "Equestrianism     4214\n",
       "Hockey            4201\n",
       "Judo              3801\n",
       "Handball          3560\n",
       "Volleyball        3404\n",
       "Basketball        3395\n",
       "Weightlifting     2996\n",
       "Water Polo        2609\n",
       "Archery           2069\n",
       "Tennis            2024\n",
       "Diving            1963\n",
       "Table Tennis      1955\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data1['sport'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fdc126ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data2 = f_data1[f_data1['team'].map(f_data1['team'].value_counts()) > 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a911f671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team\n",
       "United States     8256\n",
       "Great Britain     5661\n",
       "Australia         5497\n",
       "France            5129\n",
       "Canada            4922\n",
       "Italy             4823\n",
       "Japan             4513\n",
       "Germany           4265\n",
       "Spain             3865\n",
       "China             3766\n",
       "Hungary           3667\n",
       "Poland            3508\n",
       "Soviet Union      3293\n",
       "South Korea       3244\n",
       "Russia            3047\n",
       "Romania           3001\n",
       "Brazil            3001\n",
       "Netherlands       2862\n",
       "Sweden            2633\n",
       "West Germany      2504\n",
       "Bulgaria          2255\n",
       "East Germany      2092\n",
       "Cuba              2080\n",
       "Mexico            2072\n",
       "Switzerland       2020\n",
       "Argentina         1894\n",
       "Ukraine           1863\n",
       "New Zealand       1842\n",
       "Czechoslovakia    1683\n",
       "Greece            1549\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data2['team'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "92ebeee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1996    8383\n",
       "1988    8350\n",
       "2004    8170\n",
       "2000    8108\n",
       "2008    8070\n",
       "1992    7837\n",
       "2016    7670\n",
       "2012    7534\n",
       "1972    7342\n",
       "1976    6654\n",
       "1968    6187\n",
       "1984    6007\n",
       "1964    5448\n",
       "1980    5047\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data2['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb47f60",
   "metadata": {},
   "source": [
    "# Over all filters:\n",
    "Season: Summer only\n",
    "Year: >1960 only\n",
    "SPorts that had more than 1500 values\n",
    "Team: that had more than 1500 values\n",
    "    removed rep. columns like noc, event, etc.\n",
    "    removing weight column as it is highly correlated to height column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083794ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "026e8ac4",
   "metadata": {},
   "source": [
    "# Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3b74dd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>sport</th>\n",
       "      <th>medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>80</td>\n",
       "      <td>China</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>60</td>\n",
       "      <td>China</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>125</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2016</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Weightlifting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>70</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1984</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Water Polo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1988</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158142</th>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2000</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158143</th>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>76</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2004</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Athina</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158144</th>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>United States</td>\n",
       "      <td>1972</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Football</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158145</th>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2000</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Rowing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158146</th>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2004</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Athina</td>\n",
       "      <td>Rowing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100807 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  age  weight           team  year  season            city  \\\n",
       "0        M   24      80          China  1992  Summer       Barcelona   \n",
       "1        M   23      60          China  2012  Summer          London   \n",
       "7        F   22     125        Romania  2016  Summer  Rio de Janeiro   \n",
       "10       M   26      70    Netherlands  1984  Summer     Los Angeles   \n",
       "13       F   22      70    Netherlands  1988  Summer           Seoul   \n",
       "...     ..  ...     ...            ...   ...     ...             ...   \n",
       "158142   M   23      76      Argentina  2000  Summer          Sydney   \n",
       "158143   M   27      76      Argentina  2004  Summer          Athina   \n",
       "158144   M   21      75  United States  1972  Summer          Munich   \n",
       "158145   M   24      72         Russia  2000  Summer          Sydney   \n",
       "158146   M   28      72         Russia  2004  Summer          Athina   \n",
       "\n",
       "                sport  medal  \n",
       "0          Basketball      1  \n",
       "1                Judo      1  \n",
       "7       Weightlifting      1  \n",
       "10         Water Polo      1  \n",
       "13             Hockey      1  \n",
       "...               ...    ...  \n",
       "158142         Hockey      1  \n",
       "158143         Hockey      1  \n",
       "158144       Football      1  \n",
       "158145         Rowing      1  \n",
       "158146         Rowing      1  \n",
       "\n",
       "[100807 rows x 9 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8e1ee87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data2 = f_data2.drop(['height'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "55b8782e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': 2, 'team': 30, 'season': 1, 'city': 14, 'sport': 24}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{column: len(f_data2[column].unique()) for column in f_data2.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8faacae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(df, columns, positive_values):\n",
    "    df = df.copy()\n",
    "    for column, positive_value in zip(columns, positive_values):\n",
    "        df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n",
    "    return df\n",
    "\n",
    "def onehot_encode(df, columns, prefixes):\n",
    "    df = df.copy()\n",
    "    for column, prefix in zip(columns, prefixes):\n",
    "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(column, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948e5a4",
   "metadata": {},
   "source": [
    "#df = binary_encode(\n",
    "    f_data2,\n",
    "    columns=['sex', 'season'],\n",
    "    positive_values=['M', 'Summer']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dbdbb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = onehot_encode(\n",
    "    f_data2,\n",
    "    columns=['sex','team', 'city', 'sport'],\n",
    "    prefixes=['sex','t', 'c', 's']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "97ebd2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining non-numeric columns: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining non-numeric columns:\", len(df1.select_dtypes('object').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5d734918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100807 entries, 0 to 158146\n",
      "Data columns (total 75 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   age               100807 non-null  int64 \n",
      " 1   weight            100807 non-null  int64 \n",
      " 2   year              100807 non-null  int16 \n",
      " 3   season            100807 non-null  object\n",
      " 4   medal             100807 non-null  int64 \n",
      " 5   sex_F             100807 non-null  bool  \n",
      " 6   sex_M             100807 non-null  bool  \n",
      " 7   t_Argentina       100807 non-null  bool  \n",
      " 8   t_Australia       100807 non-null  bool  \n",
      " 9   t_Brazil          100807 non-null  bool  \n",
      " 10  t_Bulgaria        100807 non-null  bool  \n",
      " 11  t_Canada          100807 non-null  bool  \n",
      " 12  t_China           100807 non-null  bool  \n",
      " 13  t_Cuba            100807 non-null  bool  \n",
      " 14  t_Czechoslovakia  100807 non-null  bool  \n",
      " 15  t_East Germany    100807 non-null  bool  \n",
      " 16  t_France          100807 non-null  bool  \n",
      " 17  t_Germany         100807 non-null  bool  \n",
      " 18  t_Great Britain   100807 non-null  bool  \n",
      " 19  t_Greece          100807 non-null  bool  \n",
      " 20  t_Hungary         100807 non-null  bool  \n",
      " 21  t_Italy           100807 non-null  bool  \n",
      " 22  t_Japan           100807 non-null  bool  \n",
      " 23  t_Mexico          100807 non-null  bool  \n",
      " 24  t_Netherlands     100807 non-null  bool  \n",
      " 25  t_New Zealand     100807 non-null  bool  \n",
      " 26  t_Poland          100807 non-null  bool  \n",
      " 27  t_Romania         100807 non-null  bool  \n",
      " 28  t_Russia          100807 non-null  bool  \n",
      " 29  t_South Korea     100807 non-null  bool  \n",
      " 30  t_Soviet Union    100807 non-null  bool  \n",
      " 31  t_Spain           100807 non-null  bool  \n",
      " 32  t_Sweden          100807 non-null  bool  \n",
      " 33  t_Switzerland     100807 non-null  bool  \n",
      " 34  t_Ukraine         100807 non-null  bool  \n",
      " 35  t_United States   100807 non-null  bool  \n",
      " 36  t_West Germany    100807 non-null  bool  \n",
      " 37  c_Athina          100807 non-null  bool  \n",
      " 38  c_Atlanta         100807 non-null  bool  \n",
      " 39  c_Barcelona       100807 non-null  bool  \n",
      " 40  c_Beijing         100807 non-null  bool  \n",
      " 41  c_London          100807 non-null  bool  \n",
      " 42  c_Los Angeles     100807 non-null  bool  \n",
      " 43  c_Mexico City     100807 non-null  bool  \n",
      " 44  c_Montreal        100807 non-null  bool  \n",
      " 45  c_Moskva          100807 non-null  bool  \n",
      " 46  c_Munich          100807 non-null  bool  \n",
      " 47  c_Rio de Janeiro  100807 non-null  bool  \n",
      " 48  c_Seoul           100807 non-null  bool  \n",
      " 49  c_Sydney          100807 non-null  bool  \n",
      " 50  c_Tokyo           100807 non-null  bool  \n",
      " 51  s_Archery         100807 non-null  bool  \n",
      " 52  s_Athletics       100807 non-null  bool  \n",
      " 53  s_Basketball      100807 non-null  bool  \n",
      " 54  s_Boxing          100807 non-null  bool  \n",
      " 55  s_Canoeing        100807 non-null  bool  \n",
      " 56  s_Cycling         100807 non-null  bool  \n",
      " 57  s_Diving          100807 non-null  bool  \n",
      " 58  s_Equestrianism   100807 non-null  bool  \n",
      " 59  s_Fencing         100807 non-null  bool  \n",
      " 60  s_Football        100807 non-null  bool  \n",
      " 61  s_Gymnastics      100807 non-null  bool  \n",
      " 62  s_Handball        100807 non-null  bool  \n",
      " 63  s_Hockey          100807 non-null  bool  \n",
      " 64  s_Judo            100807 non-null  bool  \n",
      " 65  s_Rowing          100807 non-null  bool  \n",
      " 66  s_Sailing         100807 non-null  bool  \n",
      " 67  s_Shooting        100807 non-null  bool  \n",
      " 68  s_Swimming        100807 non-null  bool  \n",
      " 69  s_Table Tennis    100807 non-null  bool  \n",
      " 70  s_Tennis          100807 non-null  bool  \n",
      " 71  s_Volleyball      100807 non-null  bool  \n",
      " 72  s_Water Polo      100807 non-null  bool  \n",
      " 73  s_Weightlifting   100807 non-null  bool  \n",
      " 74  s_Wrestling       100807 non-null  bool  \n",
      "dtypes: bool(70), int16(1), int64(3), object(1)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8b2f4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['season'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ce549122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100807 entries, 0 to 158146\n",
      "Data columns (total 74 columns):\n",
      " #   Column            Non-Null Count   Dtype\n",
      "---  ------            --------------   -----\n",
      " 0   age               100807 non-null  int64\n",
      " 1   weight            100807 non-null  int64\n",
      " 2   year              100807 non-null  int16\n",
      " 3   medal             100807 non-null  int64\n",
      " 4   sex_F             100807 non-null  bool \n",
      " 5   sex_M             100807 non-null  bool \n",
      " 6   t_Argentina       100807 non-null  bool \n",
      " 7   t_Australia       100807 non-null  bool \n",
      " 8   t_Brazil          100807 non-null  bool \n",
      " 9   t_Bulgaria        100807 non-null  bool \n",
      " 10  t_Canada          100807 non-null  bool \n",
      " 11  t_China           100807 non-null  bool \n",
      " 12  t_Cuba            100807 non-null  bool \n",
      " 13  t_Czechoslovakia  100807 non-null  bool \n",
      " 14  t_East Germany    100807 non-null  bool \n",
      " 15  t_France          100807 non-null  bool \n",
      " 16  t_Germany         100807 non-null  bool \n",
      " 17  t_Great Britain   100807 non-null  bool \n",
      " 18  t_Greece          100807 non-null  bool \n",
      " 19  t_Hungary         100807 non-null  bool \n",
      " 20  t_Italy           100807 non-null  bool \n",
      " 21  t_Japan           100807 non-null  bool \n",
      " 22  t_Mexico          100807 non-null  bool \n",
      " 23  t_Netherlands     100807 non-null  bool \n",
      " 24  t_New Zealand     100807 non-null  bool \n",
      " 25  t_Poland          100807 non-null  bool \n",
      " 26  t_Romania         100807 non-null  bool \n",
      " 27  t_Russia          100807 non-null  bool \n",
      " 28  t_South Korea     100807 non-null  bool \n",
      " 29  t_Soviet Union    100807 non-null  bool \n",
      " 30  t_Spain           100807 non-null  bool \n",
      " 31  t_Sweden          100807 non-null  bool \n",
      " 32  t_Switzerland     100807 non-null  bool \n",
      " 33  t_Ukraine         100807 non-null  bool \n",
      " 34  t_United States   100807 non-null  bool \n",
      " 35  t_West Germany    100807 non-null  bool \n",
      " 36  c_Athina          100807 non-null  bool \n",
      " 37  c_Atlanta         100807 non-null  bool \n",
      " 38  c_Barcelona       100807 non-null  bool \n",
      " 39  c_Beijing         100807 non-null  bool \n",
      " 40  c_London          100807 non-null  bool \n",
      " 41  c_Los Angeles     100807 non-null  bool \n",
      " 42  c_Mexico City     100807 non-null  bool \n",
      " 43  c_Montreal        100807 non-null  bool \n",
      " 44  c_Moskva          100807 non-null  bool \n",
      " 45  c_Munich          100807 non-null  bool \n",
      " 46  c_Rio de Janeiro  100807 non-null  bool \n",
      " 47  c_Seoul           100807 non-null  bool \n",
      " 48  c_Sydney          100807 non-null  bool \n",
      " 49  c_Tokyo           100807 non-null  bool \n",
      " 50  s_Archery         100807 non-null  bool \n",
      " 51  s_Athletics       100807 non-null  bool \n",
      " 52  s_Basketball      100807 non-null  bool \n",
      " 53  s_Boxing          100807 non-null  bool \n",
      " 54  s_Canoeing        100807 non-null  bool \n",
      " 55  s_Cycling         100807 non-null  bool \n",
      " 56  s_Diving          100807 non-null  bool \n",
      " 57  s_Equestrianism   100807 non-null  bool \n",
      " 58  s_Fencing         100807 non-null  bool \n",
      " 59  s_Football        100807 non-null  bool \n",
      " 60  s_Gymnastics      100807 non-null  bool \n",
      " 61  s_Handball        100807 non-null  bool \n",
      " 62  s_Hockey          100807 non-null  bool \n",
      " 63  s_Judo            100807 non-null  bool \n",
      " 64  s_Rowing          100807 non-null  bool \n",
      " 65  s_Sailing         100807 non-null  bool \n",
      " 66  s_Shooting        100807 non-null  bool \n",
      " 67  s_Swimming        100807 non-null  bool \n",
      " 68  s_Table Tennis    100807 non-null  bool \n",
      " 69  s_Tennis          100807 non-null  bool \n",
      " 70  s_Volleyball      100807 non-null  bool \n",
      " 71  s_Water Polo      100807 non-null  bool \n",
      " 72  s_Weightlifting   100807 non-null  bool \n",
      " 73  s_Wrestling       100807 non-null  bool \n",
      "dtypes: bool(70), int16(1), int64(3)\n",
      "memory usage: 10.0 MB\n"
     ]
    }
   ],
   "source": [
    "df1.reset_index()\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6762abc",
   "metadata": {},
   "source": [
    "# Visualizing Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9e6d706c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'M'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m corr \u001b[38;5;241m=\u001b[39m \u001b[43mf_data2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(corr, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmako\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10052\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  10053\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 10054\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  10056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  10057\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1837\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1838\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1840\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/internals/managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/internals/managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1794\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1795\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M'"
     ]
    }
   ],
   "source": [
    "corr = f_data2.loc[:, :'medal'].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, vmin=-1.0, cmap='mako')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4b7c8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100807 entries, 0 to 158146\n",
      "Data columns (total 74 columns):\n",
      " #   Column            Non-Null Count   Dtype\n",
      "---  ------            --------------   -----\n",
      " 0   age               100807 non-null  int64\n",
      " 1   weight            100807 non-null  int64\n",
      " 2   year              100807 non-null  int16\n",
      " 3   medal             100807 non-null  int64\n",
      " 4   sex_F             100807 non-null  bool \n",
      " 5   sex_M             100807 non-null  bool \n",
      " 6   t_Argentina       100807 non-null  bool \n",
      " 7   t_Australia       100807 non-null  bool \n",
      " 8   t_Brazil          100807 non-null  bool \n",
      " 9   t_Bulgaria        100807 non-null  bool \n",
      " 10  t_Canada          100807 non-null  bool \n",
      " 11  t_China           100807 non-null  bool \n",
      " 12  t_Cuba            100807 non-null  bool \n",
      " 13  t_Czechoslovakia  100807 non-null  bool \n",
      " 14  t_East Germany    100807 non-null  bool \n",
      " 15  t_France          100807 non-null  bool \n",
      " 16  t_Germany         100807 non-null  bool \n",
      " 17  t_Great Britain   100807 non-null  bool \n",
      " 18  t_Greece          100807 non-null  bool \n",
      " 19  t_Hungary         100807 non-null  bool \n",
      " 20  t_Italy           100807 non-null  bool \n",
      " 21  t_Japan           100807 non-null  bool \n",
      " 22  t_Mexico          100807 non-null  bool \n",
      " 23  t_Netherlands     100807 non-null  bool \n",
      " 24  t_New Zealand     100807 non-null  bool \n",
      " 25  t_Poland          100807 non-null  bool \n",
      " 26  t_Romania         100807 non-null  bool \n",
      " 27  t_Russia          100807 non-null  bool \n",
      " 28  t_South Korea     100807 non-null  bool \n",
      " 29  t_Soviet Union    100807 non-null  bool \n",
      " 30  t_Spain           100807 non-null  bool \n",
      " 31  t_Sweden          100807 non-null  bool \n",
      " 32  t_Switzerland     100807 non-null  bool \n",
      " 33  t_Ukraine         100807 non-null  bool \n",
      " 34  t_United States   100807 non-null  bool \n",
      " 35  t_West Germany    100807 non-null  bool \n",
      " 36  c_Athina          100807 non-null  bool \n",
      " 37  c_Atlanta         100807 non-null  bool \n",
      " 38  c_Barcelona       100807 non-null  bool \n",
      " 39  c_Beijing         100807 non-null  bool \n",
      " 40  c_London          100807 non-null  bool \n",
      " 41  c_Los Angeles     100807 non-null  bool \n",
      " 42  c_Mexico City     100807 non-null  bool \n",
      " 43  c_Montreal        100807 non-null  bool \n",
      " 44  c_Moskva          100807 non-null  bool \n",
      " 45  c_Munich          100807 non-null  bool \n",
      " 46  c_Rio de Janeiro  100807 non-null  bool \n",
      " 47  c_Seoul           100807 non-null  bool \n",
      " 48  c_Sydney          100807 non-null  bool \n",
      " 49  c_Tokyo           100807 non-null  bool \n",
      " 50  s_Archery         100807 non-null  bool \n",
      " 51  s_Athletics       100807 non-null  bool \n",
      " 52  s_Basketball      100807 non-null  bool \n",
      " 53  s_Boxing          100807 non-null  bool \n",
      " 54  s_Canoeing        100807 non-null  bool \n",
      " 55  s_Cycling         100807 non-null  bool \n",
      " 56  s_Diving          100807 non-null  bool \n",
      " 57  s_Equestrianism   100807 non-null  bool \n",
      " 58  s_Fencing         100807 non-null  bool \n",
      " 59  s_Football        100807 non-null  bool \n",
      " 60  s_Gymnastics      100807 non-null  bool \n",
      " 61  s_Handball        100807 non-null  bool \n",
      " 62  s_Hockey          100807 non-null  bool \n",
      " 63  s_Judo            100807 non-null  bool \n",
      " 64  s_Rowing          100807 non-null  bool \n",
      " 65  s_Sailing         100807 non-null  bool \n",
      " 66  s_Shooting        100807 non-null  bool \n",
      " 67  s_Swimming        100807 non-null  bool \n",
      " 68  s_Table Tennis    100807 non-null  bool \n",
      " 69  s_Tennis          100807 non-null  bool \n",
      " 70  s_Volleyball      100807 non-null  bool \n",
      " 71  s_Water Polo      100807 non-null  bool \n",
      " 72  s_Weightlifting   100807 non-null  bool \n",
      " 73  s_Wrestling       100807 non-null  bool \n",
      "dtypes: bool(70), int16(1), int64(3)\n",
      "memory usage: 10.0 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "24aa01e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'team'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8255\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8258\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/86595857-4c87-4db3-814d-b3b9191f5ae5/3.8/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'team'"
     ]
    }
   ],
   "source": [
    "grouped_data = df1.groupby('team')['medal'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a578ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e2315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70389aee",
   "metadata": {},
   "source": [
    "# Splitting/Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "95121b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['medal'].copy()\n",
    "X = df1.drop('medal', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6bbc24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4afe6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eceb91",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "14d729e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100807, 73)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "25e41d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution (Positive to Negative): 100.0% / 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Distribution (Positive to Negative): {:.1f}% / {:.1f}%\".format(y_train.mean() * 100, (1 - y_train.mean()) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b597147",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X.shape[1]))\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c292cc",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ab697",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3201dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_test)\n",
    "y_pred = np.squeeze(np.array(model.predict(X_test) >= 0.5, dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\\n\", classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b61d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a33601",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9cb101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
