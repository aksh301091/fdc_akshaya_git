{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8040318b",
   "metadata": {},
   "source": [
    "# install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pip\n",
      "  Downloading pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.1.2\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting snowflake-snowpark-python==1.9.0\n",
      "  Downloading snowflake_snowpark_python-1.9.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fosforio\n",
      "  Downloading fosforio-1.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fosforml\n",
      "  Downloading fosforml-1.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting holidays\n",
      "  Downloading holidays-0.52-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting faker\n",
      "  Downloading Faker-26.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting snowflake-connector-python[pandas]\n",
      "  Downloading snowflake_connector_python-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m250.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setuptools>=40.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting wheel (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.1.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi<2.0.0,>=1.9 (from snowflake-connector-python[pandas])\n",
      "  Downloading cffi-1.16.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography<43.0.0,>=3.1.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading cryptography-42.0.8-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading pyOpenSSL-24.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyjwt<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pytz (from snowflake-connector-python[pandas])\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging (from snowflake-connector-python[pandas])\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from snowflake-connector-python[pandas])\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from snowflake-connector-python[pandas])\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from snowflake-connector-python[pandas])\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python[pandas])\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting platformdirs<5.0.0,>=2.6.0 (from snowflake-connector-python[pandas])\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tomlkit (from snowflake-connector-python[pandas])\n",
      "  Downloading tomlkit-0.12.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Downloading urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m215.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow (from snowflake-connector-python[pandas])\n",
      "  Downloading pyarrow-16.1.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "INFO: pip is looking at multiple versions of fosforml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fosforml\n",
      "  Downloading fosforml-1.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting requests-toolbelt==0.9.1 (from fosforml)\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting shutils==0.1.0 (from fosforml)\n",
      "  Downloading shutils-0.1.0.tar.gz (2.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting mosaic-utils (from fosforml)\n",
      "  Downloading mosaic_utils-1.0.2-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m241.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting configparser (from shutils==0.1.0->fosforml)\n",
      "  Downloading configparser-7.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pymysql (from shutils==0.1.0->fosforml)\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting six>=1.5 (from python-dateutil)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pycparser (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas])\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading snowflake_snowpark_python-1.9.0-py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fosforio-1.0.2-py3-none-any.whl (20 kB)\n",
      "Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m267.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fosforml-1.0.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m223.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m341.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m163.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m283.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m198.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m258.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m279.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m330.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m303.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m278.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading holidays-0.52-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m349.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Faker-26.0.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m331.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m280.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m311.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.16.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.7/444.7 kB\u001b[0m \u001b[31m328.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m292.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 kB\u001b[0m \u001b[31m330.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-42.0.8-cp37-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m304.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading fonttools-4.53.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m311.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m270.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m324.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m333.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m247.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m316.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyOpenSSL-24.1.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m296.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m336.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m233.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m241.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m355.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading snowflake_connector_python-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m315.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m345.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mosaic_utils-1.0.2-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m264.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m191.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m234.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.1.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.5-py3-none-any.whl (37 kB)\n",
      "Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m240.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading configparser-7.0.0-py3-none-any.whl (16 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m290.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m225.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: shutils\n",
      "  Building wheel for shutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shutils: filename=shutils-0.1.0-py3-none-any.whl size=3274 sha256=b430513dbec973369b26927cffc323a57a9c6247677d2e8e3e73e1b2c655ad9c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4_ndmwf6/wheels/c7/06/1a/4df9f03d511efd19a10f2086f67c38cf14757b555f4f24bd6e\n",
      "Successfully built shutils\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio fosforml numpy pandas matplotlib scikit-learn xgboost seaborn python-dateutil tqdm holidays faker\n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef66af3",
   "metadata": {},
   "source": [
    "# Import helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983cfe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection manager service url initialised to http://fdc-project-manager:80/project-manager\n",
      "If you need to update its value then update the variable CONNECTION_MANAGER_BASE_URL in os env.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-jh534hqx because the default path (/home/mosaic-ai/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "from time import sleep\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c7d04",
   "metadata": {},
   "source": [
    "# connect to snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53efc342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection object created: <snowflake.connector.connection.SnowflakeConnection object at 0x7fe54c1586a0>\n",
      "Please close the connection after use!\n",
      "Reading dataframe from snowflake native connector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARRIVAL_DATE_TRANSFORMED</th>\n",
       "      <th>RESERVATION_STATUS_DATE_TRANSFORMED</th>\n",
       "      <th>HOTEL</th>\n",
       "      <th>IS_CANCELED</th>\n",
       "      <th>LEAD_TIME</th>\n",
       "      <th>ARRIVAL_DATE_YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>ARRIVAL_DATE_WEEK_NUMBER</th>\n",
       "      <th>ARRIVAL_DATE_DAY_OF_MONTH</th>\n",
       "      <th>EXPECTED_ARRIVAL_DATE</th>\n",
       "      <th>RESERVATION_STATUS</th>\n",
       "      <th>RESERVATION_STATUS_DATE</th>\n",
       "      <th>TOTAL_STAY_NIGHTS</th>\n",
       "      <th>TALLY_DAYS</th>\n",
       "      <th>STAYS_IN_WEEKEND_NIGHTS</th>\n",
       "      <th>STAYS_IN_WEEK_NIGHTS</th>\n",
       "      <th>ADULTS</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>BABIES</th>\n",
       "      <th>TOTAL_GUESTS</th>\n",
       "      <th>AVG_ROOMS_PER_NIGHT</th>\n",
       "      <th>TOTAL_ROOM_NIGHTS</th>\n",
       "      <th>MEAL</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>MARKET_SEGMENT</th>\n",
       "      <th>DISTRIBUTION_CHANNEL</th>\n",
       "      <th>PREVIOUS_CANCELLATIONS</th>\n",
       "      <th>PREVIOUS_BOOKINGS_NOT_CANCELED</th>\n",
       "      <th>RESERVED_ROOM_TYPE</th>\n",
       "      <th>ASSIGNED_ROOM_TYPE</th>\n",
       "      <th>DEPOSIT_TYPE</th>\n",
       "      <th>DAYS_IN_WAITING_LIST</th>\n",
       "      <th>CUSTOMER_TYPE</th>\n",
       "      <th>ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>16-07-2021</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>17-10-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient.Party</td>\n",
       "      <td>62.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>20-08-2021</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>17-10-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient.Party</td>\n",
       "      <td>62.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>02-07-2021</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>17-10-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient.Party</td>\n",
       "      <td>62.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>20-08-2021</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>17-10-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient.Party</td>\n",
       "      <td>62.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>23-07-2021</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>17-10-2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient.Party</td>\n",
       "      <td>62.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109706</th>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>24-08-2023</td>\n",
       "      <td>Check.Out</td>\n",
       "      <td>10-09-2023</td>\n",
       "      <td>17</td>\n",
       "      <td>17.000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Offline TA/TO</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>84.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109707</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>31-08-2023</td>\n",
       "      <td>Check.Out</td>\n",
       "      <td>10-09-2023</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Offline TA/TO</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>89.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109708</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>29-08-2023</td>\n",
       "      <td>Check.Out</td>\n",
       "      <td>12-09-2023</td>\n",
       "      <td>14</td>\n",
       "      <td>14.000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>BB</td>\n",
       "      <td>IRL</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>153.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109709</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>31-08-2023</td>\n",
       "      <td>Check.Out</td>\n",
       "      <td>14-09-2023</td>\n",
       "      <td>14</td>\n",
       "      <td>14.000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>HB</td>\n",
       "      <td>DEU</td>\n",
       "      <td>Offline TA/TO</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>99.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109710</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>31-08-2023</td>\n",
       "      <td>Check.Out</td>\n",
       "      <td>14-09-2023</td>\n",
       "      <td>14</td>\n",
       "      <td>14.000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>HB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Offline TA/TO</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>112.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109711 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARRIVAL_DATE_TRANSFORMED RESERVATION_STATUS_DATE_TRANSFORMED  \\\n",
       "0                    2021-07-16                          2020-10-17   \n",
       "1                    2021-08-20                          2020-10-17   \n",
       "2                    2021-07-02                          2020-10-17   \n",
       "3                    2021-08-20                          2020-10-17   \n",
       "4                    2021-07-23                          2020-10-17   \n",
       "...                         ...                                 ...   \n",
       "109706               2023-08-24                          2023-09-10   \n",
       "109707               2023-08-31                          2023-09-10   \n",
       "109708               2023-08-29                          2023-09-12   \n",
       "109709               2023-08-31                          2023-09-14   \n",
       "109710               2023-08-31                          2023-09-14   \n",
       "\n",
       "               HOTEL  IS_CANCELED  LEAD_TIME  ARRIVAL_DATE_YEAR  MONTH  \\\n",
       "0         City Hotel            1        272               2021      7   \n",
       "1         City Hotel            1        307               2021      8   \n",
       "2         City Hotel            1        258               2021      7   \n",
       "3         City Hotel            1        307               2021      8   \n",
       "4         City Hotel            1        279               2021      7   \n",
       "...              ...          ...        ...                ...    ...   \n",
       "109706  Resort Hotel            0        269               2023      8   \n",
       "109707  Resort Hotel            0        212               2023      8   \n",
       "109708  Resort Hotel            0        204               2023      8   \n",
       "109709  Resort Hotel            0        161               2023      8   \n",
       "109710  Resort Hotel            0        211               2023      8   \n",
       "\n",
       "        ARRIVAL_DATE_WEEK_NUMBER  ARRIVAL_DATE_DAY_OF_MONTH  \\\n",
       "0                             29                         16   \n",
       "1                             34                         20   \n",
       "2                             27                          2   \n",
       "3                             34                         20   \n",
       "4                             30                         23   \n",
       "...                          ...                        ...   \n",
       "109706                        34                         24   \n",
       "109707                        35                         31   \n",
       "109708                        35                         29   \n",
       "109709                        35                         31   \n",
       "109710                        35                         31   \n",
       "\n",
       "       EXPECTED_ARRIVAL_DATE RESERVATION_STATUS RESERVATION_STATUS_DATE  \\\n",
       "0                 16-07-2021           Canceled              17-10-2020   \n",
       "1                 20-08-2021           Canceled              17-10-2020   \n",
       "2                 02-07-2021           Canceled              17-10-2020   \n",
       "3                 20-08-2021           Canceled              17-10-2020   \n",
       "4                 23-07-2021           Canceled              17-10-2020   \n",
       "...                      ...                ...                     ...   \n",
       "109706            24-08-2023          Check.Out              10-09-2023   \n",
       "109707            31-08-2023          Check.Out              10-09-2023   \n",
       "109708            29-08-2023          Check.Out              12-09-2023   \n",
       "109709            31-08-2023          Check.Out              14-09-2023   \n",
       "109710            31-08-2023          Check.Out              14-09-2023   \n",
       "\n",
       "        TOTAL_STAY_NIGHTS  TALLY_DAYS  STAYS_IN_WEEKEND_NIGHTS  \\\n",
       "0                       2       0.272                        0   \n",
       "1                       2       0.307                        0   \n",
       "2                       2       0.258                        0   \n",
       "3                       2       0.307                        0   \n",
       "4                       2       0.279                        0   \n",
       "...                   ...         ...                      ...   \n",
       "109706                 17      17.000                        4   \n",
       "109707                 10      10.000                        2   \n",
       "109708                 14      14.000                        4   \n",
       "109709                 14      14.000                        4   \n",
       "109710                 14      14.000                        4   \n",
       "\n",
       "        STAYS_IN_WEEK_NIGHTS  ADULTS  CHILDREN  BABIES  TOTAL_GUESTS  \\\n",
       "0                          2       2         0       0             2   \n",
       "1                          2       2         0       0             2   \n",
       "2                          2       2         0       0             2   \n",
       "3                          2       2         0       0             2   \n",
       "4                          2       2         0       0             2   \n",
       "...                      ...     ...       ...     ...           ...   \n",
       "109706                    13       2         0       0             2   \n",
       "109707                     8       2         1       0             3   \n",
       "109708                    10       2         0       0             2   \n",
       "109709                    10       2         0       0             2   \n",
       "109710                    10       2         0       0             2   \n",
       "\n",
       "        AVG_ROOMS_PER_NIGHT  TOTAL_ROOM_NIGHTS MEAL COUNTRY MARKET_SEGMENT  \\\n",
       "0                         1                  2   BB     PRT         Groups   \n",
       "1                         1                  2   BB     PRT         Groups   \n",
       "2                         1                  2   BB     PRT         Groups   \n",
       "3                         1                  2   BB     PRT         Groups   \n",
       "4                         1                  2   BB     PRT         Groups   \n",
       "...                     ...                ...  ...     ...            ...   \n",
       "109706                    1                 17   BB     GBR  Offline TA/TO   \n",
       "109707                    1                 10   BB     GBR  Offline TA/TO   \n",
       "109708                    1                 14   BB     IRL         Direct   \n",
       "109709                    1                 14   HB     DEU  Offline TA/TO   \n",
       "109710                    1                 14   HB     GBR  Offline TA/TO   \n",
       "\n",
       "       DISTRIBUTION_CHANNEL  PREVIOUS_CANCELLATIONS  \\\n",
       "0                     TA/TO                       1   \n",
       "1                     TA/TO                       1   \n",
       "2                     TA/TO                       1   \n",
       "3                     TA/TO                       1   \n",
       "4                     TA/TO                       1   \n",
       "...                     ...                     ...   \n",
       "109706                TA/TO                       0   \n",
       "109707                TA/TO                       0   \n",
       "109708               Direct                       0   \n",
       "109709                TA/TO                       0   \n",
       "109710                TA/TO                       0   \n",
       "\n",
       "        PREVIOUS_BOOKINGS_NOT_CANCELED RESERVED_ROOM_TYPE ASSIGNED_ROOM_TYPE  \\\n",
       "0                                    0                  A                  A   \n",
       "1                                    0                  A                  A   \n",
       "2                                    0                  A                  A   \n",
       "3                                    0                  A                  A   \n",
       "4                                    0                  A                  A   \n",
       "...                                ...                ...                ...   \n",
       "109706                               0                  D                  D   \n",
       "109707                               0                  A                  A   \n",
       "109708                               0                  E                  E   \n",
       "109709                               0                  A                  A   \n",
       "109710                               0                  D                  D   \n",
       "\n",
       "       DEPOSIT_TYPE  DAYS_IN_WAITING_LIST    CUSTOMER_TYPE     ADR  \n",
       "0        No Deposit                     0  Transient.Party   62.80  \n",
       "1        No Deposit                     0  Transient.Party   62.80  \n",
       "2        No Deposit                     0  Transient.Party   62.80  \n",
       "3        No Deposit                     0  Transient.Party   62.80  \n",
       "4        No Deposit                     0  Transient.Party   62.80  \n",
       "...             ...                   ...              ...     ...  \n",
       "109706   No Deposit                     0         Contract   84.80  \n",
       "109707   No Deposit                     0        Transient   89.75  \n",
       "109708   No Deposit                     0        Transient  153.57  \n",
       "109709   No Deposit                     0        Transient   99.06  \n",
       "109710   No Deposit                     0         Contract  112.80  \n",
       "\n",
       "[109711 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowflake.get_connection(connection_name=\"TTH_REV_OPT_CXN\")\n",
    "data = get_dataframe(\"BOOKINGS_TRANSFORMED\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e2ea75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataframe from snowflake native connector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>MEAL_PREF</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>PREVIOUS_CANCELLATIONS</th>\n",
       "      <th>PREVIOUS_BOOKINGS_NOT_CANCELED</th>\n",
       "      <th>CUSTOMER_TYPE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000001</td>\n",
       "      <td>HB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000002</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0000003</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>72</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0000004</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0000005</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109706</th>\n",
       "      <td>C0109707</td>\n",
       "      <td>BB</td>\n",
       "      <td>FRA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109707</th>\n",
       "      <td>C0109708</td>\n",
       "      <td>HB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109708</th>\n",
       "      <td>C0109709</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109709</th>\n",
       "      <td>C0109710</td>\n",
       "      <td>HB</td>\n",
       "      <td>DEU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109710</th>\n",
       "      <td>C0109711</td>\n",
       "      <td>HB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109711 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CUST_ID MEAL_PREF COUNTRY  PREVIOUS_CANCELLATIONS  \\\n",
       "0       C0000001        HB     PRT                       0   \n",
       "1       C0000002        BB     PRT                       0   \n",
       "2       C0000003        BB     PRT                       0   \n",
       "3       C0000004        BB     PRT                       0   \n",
       "4       C0000005        BB     PRT                       0   \n",
       "...          ...       ...     ...                     ...   \n",
       "109706  C0109707        BB     FRA                       0   \n",
       "109707  C0109708        HB     GBR                       0   \n",
       "109708  C0109709        BB     GBR                       0   \n",
       "109709  C0109710        HB     DEU                       0   \n",
       "109710  C0109711        HB     GBR                       0   \n",
       "\n",
       "        PREVIOUS_BOOKINGS_NOT_CANCELED CUSTOMER_TYPE  AGE GENDER  \n",
       "0                                    0     Transient   25      M  \n",
       "1                                    0     Transient   37      M  \n",
       "2                                    0     Transient   72      F  \n",
       "3                                    0     Transient   51      M  \n",
       "4                                    0     Transient   70      F  \n",
       "...                                ...           ...  ...    ...  \n",
       "109706                               0     Transient   68      M  \n",
       "109707                               0      Contract   54      M  \n",
       "109708                               0     Transient   35      M  \n",
       "109709                               0     Transient   52      F  \n",
       "109710                               0      Contract   58      M  \n",
       "\n",
       "[109711 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust = get_dataframe(\"CUSTOMER_DATA\")\n",
    "cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f587230",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfaker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Faker\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize Faker to generate random data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m fake \u001b[38;5;241m=\u001b[39m Faker()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faker'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker to generate random data\n",
    "fake = Faker()\n",
    "\n",
    "# Number of rows\n",
    "num_rows = 109711\n",
    "\n",
    "# Generate the B_ID column\n",
    "b_ids = [f\"B{str(i).zfill(6)}\" for i in range(1, num_rows + 1)]\n",
    "\n",
    "# Generate random dates\n",
    "dates = [fake.date_this_decade() for _ in range(num_rows)]\n",
    "\n",
    "# Generate random amounts\n",
    "amounts = np.round(np.random.uniform(1.0, 1000.0, num_rows), 2)\n",
    "\n",
    "# Generate transaction types\n",
    "transaction_types = np.random.choice(['Credit', 'Debit'], num_rows)\n",
    "\n",
    "# Generate descriptions\n",
    "descriptions = [fake.sentence(nb_words=5) for _ in range(num_rows)]\n",
    "\n",
    "# Create the DataFrame\n",
    "datas = {\n",
    "    'B_ID': b_ids,\n",
    "    'Date': dates,\n",
    "    'Amount': amounts,\n",
    "    'Type': transaction_types,\n",
    "    'Description': descriptions\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(datas)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [x.lower() for x in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de05c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa4084",
   "metadata": {},
   "source": [
    "# removing Canceletions and no-shows and keep City hotel data only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[(data['is_canceled'] == 0) & (data['reservation_status'] !='No-Show')] \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d75d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['hotel','market_segment','reserved_room_type']).agg({'adr':'mean','reservation_status_date_transformed':'count'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[(df.market_segment != 'Complementary') ]\n",
    "data = data[(data.reserved_room_type == 'A') |(data.reserved_room_type == 'D') | (data.reserved_room_type == 'E')]\n",
    "data.reserved_room_type.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b832af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb481b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_values(row):\n",
    "    if row['hotel'] == 'City Hotel' and row['reserved_room_type'] == 'A':\n",
    "        return 460\n",
    "    elif row['hotel'] == 'City Hotel' and row['reserved_room_type'] == 'D':\n",
    "        return 135\n",
    "    elif row['hotel'] == 'City Hotel' and row['reserved_room_type'] == 'E':\n",
    "        return 30\n",
    "    elif row['hotel'] == 'Resort Hotel' and row['reserved_room_type'] == 'A':\n",
    "        return 360\n",
    "    elif row['hotel'] == 'Resort Hotel' and row['reserved_room_type'] == 'D':\n",
    "        return 125\n",
    "    elif row['hotel'] == 'Resort Hotel' and row['reserved_room_type'] == 'E':\n",
    "        return 100\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['room_limit'] = data.apply(update_values, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backup = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe078cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = data['hotel'].unique()\n",
    "room_types = data['reserved_room_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc594eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_rns'] = data['stays_in_week_nights'] + data['stays_in_weekend_nights']\n",
    "data_to_transform = data[['hotel','reserved_room_type','arrival_date_transformed','total_rns','adr', 'room_limit']]\n",
    "data_to_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark.session import Session\n",
    "user = os.getenv(\"user\")\n",
    "warehouse = os.getenv(\"warehouse\")\n",
    "schema= os.getenv(\"schema\")\n",
    "database = os.getenv(\"database\")\n",
    "role =  os.getenv(\"role\")\n",
    "account =  os.getenv(\"account\")\n",
    "password= os.getenv(\"password\")\n",
    "\n",
    "connection_params = dict(user=user, \n",
    "                         password=password, \n",
    "                         account=account, \n",
    "                         warehouse=warehouse, \n",
    "                         database=database,\n",
    "                         schema=schema, \n",
    "                         role=role)\n",
    "\n",
    "session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "session.sql('use warehouse {};'.format(warehouse)).collect()\n",
    "\n",
    "session.sql('use database {};'.format(database)).collect()\n",
    "\n",
    "session.sql('use schema {}.{};'.format(database, schema)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ef4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b8ba8a9",
   "metadata": {},
   "source": [
    "# Create a new dataframe to store the data by stay date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = pd.DataFrame()\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    num_stay_dates = row['total_rns']\n",
    "    try:\n",
    "        # Create a row for each stay date\n",
    "        expanded_booking = pd.DataFrame({\n",
    "            'hotel': row['hotel'],\n",
    "            'room_type': row['reserved_room_type'], \n",
    "            'arrival_date': pd.date_range(start=row['expected_arrival_date'], periods=num_stay_dates),\n",
    "            'total_rns': 1,\n",
    "            'adr': row['adr'],\n",
    "            'room_limit': row['room_limit']\n",
    "        })\n",
    "        \n",
    "        # Append the stay date information to the new dataframe\n",
    "        expanded_df = pd.concat([expanded_df, expanded_booking], ignore_index=True)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing booking for {row['hotel']} on {row['expected_arrival_date']} : {num_stay_dates} {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4df76",
   "metadata": {},
   "source": [
    "# Sort the final dataframe by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168594ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expanded_df = expanded_df.sort_values('arrival_date')\n",
    "expanded_df = expanded_df.reset_index(drop=True)\n",
    "expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df['adr']= np.round(expanded_df['adr'], 2)\n",
    "\n",
    "expanded_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb8a52",
   "metadata": {},
   "source": [
    "# Building seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "holiday_dates = holidays.CountryHoliday('PT', years=[2020,2021,2022,2023])\n",
    "holidays = {\n",
    "    expected_arrival_date: name\n",
    "    for expected_arrival_date, name in holiday_dates.items()\n",
    "    if name in ['Ano Novo', 'Páscoa', 'Dia de Natal']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a11810",
   "metadata": {},
   "source": [
    "# rename holiday columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cc18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57adc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = expanded_df.rename({'Ano Novo':'new_year','Páscoa':'easter','Dia de Natal':'christmas'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_holiday_dates(start_year, end_year):\n",
    "    holidays = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        holidays[datetime.date(year, 1, 1)] = 'new_year'\n",
    "        easter_date = easter(year)\n",
    "        holidays[easter_date] = 'easter'\n",
    "        holidays[datetime.date(year, 12, 25)] = 'christmas'\n",
    "    return holidays\n",
    "\n",
    "holidays = generate_holiday_dates(2020, 2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ec526",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ecf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre and post ranges for each holiday\n",
    "pre_range_offset = {'new_year': relativedelta(days=-1),\n",
    "                    'easter': relativedelta(days=-2),\n",
    "                    'christmas': relativedelta(days=-3)}\n",
    "\n",
    "post_range_offset = {'new_year': relativedelta(days=1),\n",
    "                     'easter': relativedelta(days=2),\n",
    "                     'christmas': relativedelta(days=3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafa047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for each holiday\n",
    "for holiday in holidays.values():\n",
    "    expanded_df[holiday] = 0\n",
    " \n",
    " # Set the holiday columns to 1 for matching dates\n",
    "for arrival_date, name in holidays.items():\n",
    "    expanded_df.loc[expanded_df['arrival_date'] == arrival_date, name] = 1\n",
    "\n",
    "    # Set the holiday columns to 1 for pre and post dates\n",
    "    pre_offset = pre_range_offset.get(name)\n",
    "    if pre_offset:\n",
    "        pre_date = pd.to_datetime(arrival_date) + pre_offset\n",
    "        expanded_df.loc[expanded_df['arrival_date'] == pre_date.strftime('%Y-%m-%d'), name] = 1\n",
    "\n",
    "    post_offset = post_range_offset.get(name)\n",
    "    if post_offset:\n",
    "        post_date = pd.to_datetime(arrival_date) + post_offset\n",
    "        expanded_df.loc[expanded_df['arrival_date'] == post_date.strftime('%Y-%m-%d'), name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d034b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##check\n",
    "expanded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ed484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dow, month to data\n",
    "expanded_df['dow'] = expanded_df.arrival_date.dt.strftime('%A')\n",
    "expanded_df['month'] = expanded_df.arrival_date.dt.strftime('%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116caac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##check\n",
    "expanded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df[expanded_df['easter'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df['adr'] = np.round(expanded_df['adr'], 2)\n",
    "expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1dfe5",
   "metadata": {},
   "source": [
    "# Non holidays dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8373c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_holidays = expanded_df[expanded_df[['new_year', 'easter', 'christmas']].sum(axis=1) == 0]\n",
    "\n",
    "non_holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_holidays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_rns= non_holidays.groupby(['arrival_date','dow','month', 'hotel', 'room_type']).agg({'room_limit': 'mean', 'total_rns':'sum'}).reset_index() # ge total stays per day\n",
    "\n",
    "daily_rns = daily_rns.groupby(['dow','month', 'hotel', 'room_type']).agg({'room_limit': 'mean','total_rns':['sum','mean','median']}).reset_index() # get Rns metrics by Dow & Month\n",
    "\n",
    "daily_rns.columns = ['_'.join(col) for col in daily_rns.columns] #remove multi level column\n",
    "daily_rns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_frequency = non_holidays.groupby(['dow','month','adr', 'hotel', 'room_type']).agg({'room_limit': 'mean','total_rns':'sum'})\n",
    "adr_frequency.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(adr_frequency, daily_rns,how='left',left_on=['dow','month', 'hotel', 'room_type'], right_on=['dow_','month_', 'hotel_', 'room_type_'],suffixes=('_act', '_tot'))\n",
    "\n",
    "merged_df = merged_df.drop(['dow_','month_'],axis=1)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1355c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['probability'] = merged_df['total_rns']/merged_df['total_rns_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdaa3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['expected_rns'] = merged_df['probability'] * merged_df['total_rns_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba54f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sort_values(by=['dow', 'month', 'adr'], ascending=[True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78068d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['expected_demand']=merged_df.groupby(['dow', 'month'])['expected_rns'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['expected_rev'] = merged_df['adr']* merged_df['expected_demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['expected_rev'] = merged_df['adr']* merged_df['expected_demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[(merged_df.dow == 'Friday') & (merged_df.month =='April')].plot(x='adr', y='expected_demand', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c57bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[(merged_df.dow == 'Friday') & (merged_df.month =='April')].plot(x='adr', y='expected_rev', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define the demand curve function\n",
    "def demand_curve(x, a, b, c, d, max_demand):\n",
    "    demand = a * np.exp(-b * x) + c\n",
    "    demand = np.where(x <= max_demand, np.minimum(demand, max_demand), demand)\n",
    "    return demand + d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856be003",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = merged_df['adr'].values\n",
    "y_data = merged_df['expected_demand'].values\n",
    "\n",
    "\n",
    "initial_guess = [1, 0.01, 1, 1, 100]\n",
    "bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "\n",
    "params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess)\n",
    "\n",
    "a_fit, b_fit, c_fit ,d_fit,max_demand= params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb449ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_demand = demand_curve(x_data, a_fit, b_fit,c_fit,d_fit,max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02eb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data, y_data, label='Actual Demand')\n",
    "plt.plot(x_data, predicted_demand, label='Fitted Curve')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Demand')\n",
    "plt.legend()\n",
    "plt.title('Demand Curve Fit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2582a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue(price):\n",
    "    return price * demand_curve(price, a_fit, b_fit,c_fit,d_fit,max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = lambda price: -revenue(price)\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "result = minimize_scalar(objective, bounds=(60, 180), method='bounded')\n",
    "optimal_price = result.x\n",
    "max_revenue = -result.fun\n",
    "room_sold = demand_curve(optimal_price, a_fit, b_fit,c_fit,d_fit,max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd335c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The optimal price to maximize revenue: ${optimal_price}\")\n",
    "print(f\"The maximum revenue achievable: ${max_revenue}\")\n",
    "print(f\"The expected number of rooms to sell: {room_sold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "\n",
    "def demand_to_price(num_rooms, a, b, c, d, max_demand):\n",
    "    def root_func(x):\n",
    "        return num_rooms - (a * np.exp(-b * x) + c)\n",
    "\n",
    "    try:\n",
    "        price = brentq(root_func, 0, 200)  # Adjust the interval bounds as needed\n",
    "    except ValueError:\n",
    "        # Fallback to default price if no root is found\n",
    "        price_range=(0, 200)\n",
    "        price = np.random.uniform(*price_range)\n",
    "\n",
    "    return price\n",
    "\n",
    "# from scipy.optimize import brentq\n",
    "\n",
    "# def demand_to_price(num_rooms, a, b, c, d, max_demand):\n",
    "   \n",
    "#     def root_func(x):\n",
    "#         return num_rooms - (a * np.exp(-b * x) + c)\n",
    "    \n",
    "#     # Find the price using numerical root finding\n",
    "#     price = brentq(root_func, 0, 200)  # Adjust the interval bounds as needed\n",
    "    \n",
    "#     return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_to_price(50,a_fit,b_fit,c_fit,d_fit,max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728fb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['month', 'hotel','room_limit', 'room_type', 'dow', 'optimal_rate', 'expected_rn','expected_rev','optimal_rate_lim_inv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = merged_df.month.unique()\n",
    "dow = merged_df.dow.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff451f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a loop to observe if our demand curve fits properly to each demand month and dow\n",
    "\n",
    "\n",
    "for month in months:\n",
    "    for day in dow:\n",
    "        \n",
    "        print(month,day)\n",
    "        #get data\n",
    "        data = merged_df[(merged_df.dow == day) & (merged_df.month ==month)].reset_index()\n",
    "        \n",
    "        #remove outlier\n",
    "        mean = data.adr.mean()\n",
    "        std_dev = data.adr.std()\n",
    "       \n",
    "\n",
    "        # calculate z-scores\n",
    "        data['z_scores'] = np.abs((data.adr - mean) / std_dev)\n",
    "        \n",
    "        #filter out outliers\n",
    "        data = data[data.z_scores <=2]\n",
    "        \n",
    "        ## Fit Demand curve\n",
    "        x_data = data['adr'].values\n",
    "        y_data = data['expected_demand'].values\n",
    "        \n",
    "        # Try except expression to ensure we get no errors when fitting the demand curve due to our initial guess\n",
    "        try:\n",
    "            initial_guess = [1, 0.01, 1, 1,data['total_rns_median'].values[0] ]\n",
    "            bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "\n",
    "        # Fit the demand curve to the data\n",
    "            params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess)\n",
    "        except:\n",
    "            if month =='January':\n",
    "                \n",
    "                initial_guess = [1, 0.01, 1, 1,40 ]\n",
    "            else:\n",
    "                initial_guess = [1, 0.01, 1, 1,50 ]\n",
    "            bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "\n",
    "        # Fit the demand curve to the data\n",
    "            params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess)\n",
    "        \n",
    "        # Extract the fitted parameters\n",
    "        a_fit, b_fit, c_fit ,d_fit,max_demand= params\n",
    "        \n",
    "        #visually explore if the demand curve fits the data\n",
    "        predicted_demand = demand_curve(x_data, a_fit, b_fit,c_fit,d_fit,max_demand)\n",
    "        \n",
    "        plt.scatter(x_data, y_data, label='Actual Demand')\n",
    "        plt.plot(x_data, predicted_demand, label='Fitted Curve')\n",
    "        plt.xlabel('Price')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.legend()\n",
    "        plt.title('Demand Curve Fit')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c68db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hotel in hotels:\n",
    "    for room_type in room_types:\n",
    "        for month in months:\n",
    "            for day in dow:\n",
    "                # Get data for the specific combination\n",
    "                data_subset = merged_df[(merged_df['dow'] == day) & \n",
    "                                        (merged_df['hotel'] == hotel) & \n",
    "                                        (merged_df['room_type'] == room_type) & \n",
    "                                        (merged_df['month'] == month)].reset_index()\n",
    "                \n",
    "                if data_subset.empty:\n",
    "                    continue\n",
    "\n",
    "                # Remove outliers\n",
    "                mean = data_subset['adr'].mean()\n",
    "                std_dev = data_subset['adr'].std()\n",
    "                data_subset['z_scores'] = np.abs((data_subset['adr'] - mean) / std_dev)\n",
    "                data_subset = data_subset[data_subset['z_scores'] <= 2]\n",
    "\n",
    "                # Fit demand curve\n",
    "                x_data = data_subset['adr'].values\n",
    "                y_data = data_subset['expected_demand'].values\n",
    "\n",
    "                try:\n",
    "                    initial_guess = [1, 0.01, 1, 1, data_subset['total_rns_median'].values[0]]\n",
    "                    bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "                    maxfev = 10000  # Increase the number of maximum function evaluations\n",
    "                    params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess, maxfev=maxfev)\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Error fitting demand curve for {hotel}, {room_type}, {month}, {day}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                a_fit, b_fit, c_fit, d_fit, max_demand = params\n",
    "\n",
    "                # Optimize revenue\n",
    "                def revenue(price):\n",
    "                    return price * demand_curve(price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                objective = lambda price: -revenue(price)\n",
    "                optimize = minimize_scalar(objective, bounds=(45, 200), method='bounded')\n",
    "                optimal_price = optimize.x\n",
    "                max_revenue = -optimize.fun\n",
    "                expected_rns = demand_curve(optimal_price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                optimal_rate_lim_inv = demand_to_price(data_subset['room_limit'].mean(), a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                new_row = pd.DataFrame({'hotel': hotel,\n",
    "                                        'room_type': room_type,\n",
    "                                        'room_limit': data_subset['room_limit'].mean(),\n",
    "                                        'month': month,\n",
    "                                        'dow': day,\n",
    "                                        'optimal_rate': optimal_price,\n",
    "                                        'expected_rev': max_revenue,\n",
    "                                        'expected_rn': expected_rns,\n",
    "                                        'optimal_rate_lim_inv': optimal_rate_lim_inv}, index=[0])\n",
    "                results = pd.concat([results, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fac15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa35f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Sort the dataframe by the custom order\n",
    "results['month'] = pd.Categorical(results['month'], categories=month_order, ordered=True)\n",
    "results['dow'] = pd.Categorical(results['dow'], categories=dow_order, ordered=True)\n",
    "results = results.sort_values(['month', 'dow'])\n",
    "\n",
    "grouped = results.groupby(['month', 'dow'])['optimal_rate'].mean().unstack()\n",
    "\n",
    "# Create the graph\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "grouped.plot(ax=ax, kind='bar')\n",
    "ax.set_xlabel('Day of the Week')\n",
    "ax.set_ylabel('Optimal Rate')\n",
    "ax.set_title('Optimal Rate by Month and Day of the Week')\n",
    "\n",
    "# Customize the appearance (optional)\n",
    "plt.legend(title='Month', bbox_to_anchor=(1, 1))\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc29da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the results\n",
    "results['optimal_rate'] = results['optimal_rate'].round()\n",
    "results['optimal_rate_lim_inv'] = results['optimal_rate_lim_inv'].round()\n",
    "\n",
    "results['expected_rn'] = results['expected_rn'].round().astype(int)\n",
    "results['expected_rev'] = results['expected_rev'].round()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67157075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68756d4",
   "metadata": {},
   "source": [
    "# Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays =  expanded_df[expanded_df[['new_year', 'easter', 'christmas']].sum(axis=1) != 0]\n",
    "holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4bd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivoted = pd.melt(holidays, id_vars=['arrival_date', 'total_rns', 'adr', 'dow', 'month', \"hotel\", \"room_type\", 'room_limit'],\n",
    "                    value_vars=['new_year', 'easter', 'christmas'],\n",
    "                    var_name='holiday', value_name='holiday_indicator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivoted[unpivoted.holiday =='christmas']\n",
    "unpivoted = unpivoted[unpivoted['holiday_indicator'] == 1]\n",
    "unpivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_adr = unpivoted.groupby(['holiday','adr','holiday_indicator', \"hotel\", \"room_type\"]).agg({'room_limit': 'mean', 'total_rns':'sum'}).reset_index()\n",
    "holiday_rns = unpivoted.groupby(['arrival_date','holiday', \"hotel\", \"room_type\"]).agg({'room_limit': 'mean','total_rns':'sum'}).reset_index()\n",
    "holiday_rns = holiday_rns.groupby(['holiday', \"hotel\", \"room_type\"]).agg({'room_limit': 'mean', 'total_rns':['sum','mean','median']}).reset_index()\n",
    "holiday_rns.columns = ['_'.join(col) for col in holiday_rns.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a38166",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_rns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_holidays = pd.merge(holiday_adr, holiday_rns,how='left',left_on=['holiday' ,'hotel', 'room_type'], right_on=['holiday_' ,'hotel_', 'room_type_'],suffixes=('_act', '_tot'))\n",
    "\n",
    "merged_holidays.drop('holiday_',axis=1,inplace=True)\n",
    "\n",
    "merged_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa72a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_holidays['probability'] = merged_holidays['total_rns']/merged_holidays['total_rns_sum']\n",
    "merged_holidays['expected_rns'] = merged_holidays['probability'] * merged_holidays['total_rns_median']\n",
    "merged_holidays = merged_holidays.sort_values(by=['holiday', 'adr'], ascending=[True, False])\n",
    "merged_holidays['expected_demand']=merged_holidays.groupby(['holiday'])['expected_rns'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_holidays = merged_holidays.holiday.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f66b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_to_price(num_rooms, a, b, c, d, max_demand):\n",
    "    def root_func(x):\n",
    "        return num_rooms - (a * np.exp(-b * x) + c)\n",
    "\n",
    "    try:\n",
    "        price = brentq(root_func, 0, 200)  # Adjust the interval bounds as needed\n",
    "    except ValueError:\n",
    "        # Fallback to default price if no root is found\n",
    "        price_range=(0, 200)\n",
    "        price = np.random.uniform(*price_range)\n",
    "\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0febbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_results = pd.DataFrame(columns=['holiday', 'optimal_rate', 'expected_rn','expected_rev','optimal_rate_lim_inv'])\n",
    "\n",
    "for hotel in hotels:\n",
    "    for room_type in room_types:\n",
    "\n",
    "        for day in unique_holidays:\n",
    "                data = merged_holidays[(merged_holidays.holiday == day) & (merged_holidays.hotel == hotel) & (merged_holidays.room_type == room_type) ].reset_index()\n",
    "\n",
    "                #remove outlier\n",
    "                mean = data.adr.mean()\n",
    "                std_dev = data.adr.std()\n",
    "\n",
    "\n",
    "                # calculate z-scores\n",
    "                data['z_scores'] = np.abs((data.adr - mean) / std_dev)\n",
    "\n",
    "                #filter out outliers\n",
    "                data = data[data.z_scores <=2]\n",
    "\n",
    "                ## Fit Demand curve\n",
    "                x_data = data['adr'].values\n",
    "                y_data = data['expected_demand'].values\n",
    "\n",
    "                initial_guess = [1, 0.01, 1, 1,data['total_rns_median'].values[0] ]\n",
    "                bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "\n",
    "                try:\n",
    "                    params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fitting demand curve for {hotel}, {room_type}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Extract the fitted parameters\n",
    "                a_fit, b_fit, c_fit ,d_fit,max_demand= params\n",
    "\n",
    "                a_fit, b_fit, c_fit ,d_fit,max_demand = np.round(a_fit, 3), np.round(b_fit, 3), np.round(c_fit, 3) ,np.round(d_fit, 3),np.round(max_demand, 3)\n",
    "                #optimze revenue\n",
    "                objective = lambda price: -revenue(price)\n",
    "\n",
    "\n",
    "\n",
    "                optimize = minimize_scalar(objective, bounds=(45, 400), method='bounded')\n",
    "                optimal_price = optimize.x\n",
    "                max_revenue = -optimize.fun\n",
    "\n",
    "                expected_rns = demand_curve(optimal_price,a_fit, b_fit, c_fit ,d_fit,max_demand)\n",
    "                print(50,a_fit,b_fit,c_fit,d_fit,max_demand)\n",
    "                optimal_rate_lim_inv = demand_to_price(data.room_limit.mean() ,a_fit,b_fit,c_fit,d_fit,max_demand)\n",
    "\n",
    "                new_row = pd.DataFrame({'holiday':day,\n",
    "                                        'hotel': hotel,\n",
    "                                        'room_limit': data.room_limit.mean(),\n",
    "                               'room_type': room_type,\n",
    "                               'optimal_rate': optimal_price,\n",
    "                               'expected_rev':max_revenue,\n",
    "                               'expected_rn':expected_rns,\n",
    "                               'optimal_rate_lim_inv':optimal_rate_lim_inv},index=[0])\n",
    "                holiday_results = pd.concat([holiday_results, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e864db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_results\n",
    "\n",
    "\n",
    "years = [2020, 2021, 2022, 2023]\n",
    "\n",
    "holiday_dates = []\n",
    "for year in years:\n",
    "    for index, row in holiday_results.iterrows():\n",
    "        if row['holiday'] == 'christmas':\n",
    "            date = datetime.date(year, 12, 25)\n",
    "        elif row['holiday'] == 'easter':\n",
    "            date = easter(year)\n",
    "        elif row['holiday'] == 'new_year':\n",
    "            date = datetime.date(year, 1, 1)\n",
    "\n",
    "        holiday_dates.append({\n",
    "            'hotel': row['hotel'],\n",
    "            'room_type': row['room_type'],\n",
    "            'month': date.strftime('%B'),\n",
    "            'dow': date.strftime(\"%A\"),\n",
    "            'holiday': row['holiday'],\n",
    "            'optimal_rate': row['optimal_rate'],\n",
    "            'expected_rn': row['expected_rn'],\n",
    "            'expected_rev': row['expected_rev'],\n",
    "            'optimal_rate_lim_inv': row['optimal_rate_lim_inv'],\n",
    "            'arrival_date': pd.to_datetime(date)\n",
    "        })\n",
    "\n",
    "holiday_results_yearly = pd.DataFrame(holiday_dates)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_results_yearly[holiday_results_yearly.holiday == 'new_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[(results['month'] == 'April') & (results['room_type'] == 'A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee610e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "hotel_types = ['Resort Hotel', 'City Hotel']\n",
    "room_types = ['A', 'D', 'E']\n",
    "\n",
    "combinations = list(itertools.product(hotel_types, room_types))\n",
    "\n",
    "combinations\n",
    "\n",
    "combinations_df = pd.DataFrame(combinations, columns=['hotel', 'room_type'])\n",
    "combinations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3dab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {month: index for index, month in enumerate(pd.date_range('2020-01-01', periods=12, freq='M').strftime('%B'), 1)}\n",
    "\n",
    "\n",
    "new_data = pd.DataFrame()\n",
    "\n",
    "for year in range(2020, 2024):\n",
    "    for month in month_dict.values():\n",
    "        start_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1)\n",
    "        end_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1) + pd.offsets.MonthEnd(0)\n",
    "        date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "        df = pd.DataFrame(date_range, columns=['arrival_date'])\n",
    "        df['dow'] = df['arrival_date'].dt.day_name()\n",
    "        df['month'] = df['arrival_date'].dt.month_name()\n",
    "\n",
    "        result_df = df.assign(key=1).merge(combinations_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "        new_data = pd.concat([new_data, result_df], ignore_index=True)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.merge(new_data, results, how='left', on=['dow', 'hotel', 'room_type', 'month'])\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_results_yearly['arrival_date'] = pd.to_datetime(holiday_results_yearly['arrival_date'])\n",
    "final_data['arrival_date'] = pd.to_datetime(final_data['arrival_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(final_data, holiday_results_yearly[['arrival_date', 'hotel', 'room_type', 'month', 'dow', 'optimal_rate', 'expected_rn', 'expected_rev', 'optimal_rate_lim_inv']], how='left', on=['arrival_date', 'hotel','room_type','month'], suffixes=('', '_holiday'))\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df.arrival_date == '2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aefe7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['optimal_rate'] = merged_df['optimal_rate_holiday'].combine_first(final_data['optimal_rate'])\n",
    "final_data['expected_rn'] = merged_df['expected_rn_holiday'].combine_first(final_data['expected_rn'])\n",
    "final_data['expected_rev'] = merged_df['expected_rev_holiday'].combine_first(final_data['expected_rev'])\n",
    "final_data['optimal_rate_lim_inv'] = merged_df['optimal_rate_lim_inv_holiday'].combine_first(final_data['optimal_rate_lim_inv'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac880b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797be7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcf1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backup['arrival_date_transformed'] = pd.to_datetime(data_backup['arrival_date_transformed'])\n",
    "final_data['arrival_date'] = pd.to_datetime(final_data['arrival_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_opt_booking = pd.merge(data_backup, final_data, right_on=['arrival_date', 'hotel', 'room_type'], left_on=['arrival_date_transformed', 'hotel', 'reserved_room_type'], how='left')\n",
    "rev_opt_booking.to_csv('rev_opt_booking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5443b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_opt_booking.columns = map(lambda x: str(x).upper(), rev_opt_booking.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_opt_booking[\"ARRIVAL_DATE\"] = pd.to_datetime(rev_opt_booking[\"ARRIVAL_DATE\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "rev_opt_booking[\"ARRIVAL_DATE_TRANSFORMED\"] = pd.to_datetime(rev_opt_booking[\"ARRIVAL_DATE_TRANSFORMED\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=session.createDataFrame(\n",
    "        rev_opt_booking.values.tolist(),\n",
    "        schema=rev_opt_booking.columns.tolist())\n",
    "df_model.write.mode(\"overwrite\").save_as_table(\"TTH_DB.TTH_REV_OPT_Schema.REV_OPT_BOOKING_CLEANED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c95ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_opt_booking.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
