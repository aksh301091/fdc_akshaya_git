{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio fosforml numpy pandas matplotlib scikit-learn xgboost seaborn python-dateutil tqdm holidays faker\n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bbc66",
   "metadata": {},
   "source": [
    "# Importing helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dac850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-gmjh633l because the default path (/home/mosaic-ai/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "from time import sleep\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "import holidays, itertools\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.types import StringType\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f4004",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake.get_connection(connection_name=\"TTH_REV_OPT_CXN\")\n",
    "data = get_dataframe(\"BOOKINGS_TRANSFORMED\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cabb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = map(lambda x: str(x).lower(), data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_values(row):\n",
    "    if row['hotel'] == 'City Hotel' and row['reserved_room_type'] == 'A':\n",
    "        return 150\n",
    "    elif row['hotel'] == 'City Hotel' and row['reserved_room_type'] == 'D':\n",
    "        return 80\n",
    "    elif row['hotel'] == 'City Hotel' and row['reserved_room_type'] == 'E':\n",
    "        return 30\n",
    "    elif row['hotel'] == 'Resort Hotel' and row['reserved_room_type'] == 'A':\n",
    "        return 150\n",
    "    elif row['hotel'] == 'Resort Hotel' and row['reserved_room_type'] == 'D':\n",
    "        return 75\n",
    "    elif row['hotel'] == 'Resort Hotel' and row['reserved_room_type'] == 'E':\n",
    "        return 60\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['room_limit'] = data.apply(update_values, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f426ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = data['hotel'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1323b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75255b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define the demand curve function\n",
    "def demand_curve(x, a, b, c, d, max_demand):\n",
    "    demand = a * np.exp(-b * x) + c\n",
    "    demand = np.where(x <= max_demand, np.minimum(demand, max_demand), demand)\n",
    "    return demand + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue(price):\n",
    "    return price * demand_curve(price, a_fit, b_fit,c_fit,d_fit,max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f97a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b44e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_holiday_dates(start_year, end_year):\n",
    "    holidays = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        holidays[datetime.date(year, 1, 1)] = 'new_year'\n",
    "        easter_date = easter(year)\n",
    "        holidays[easter_date] = 'easter'\n",
    "        holidays[datetime.date(year, 12, 25)] = 'christmas'\n",
    "    return holidays\n",
    "\n",
    "holidays = generate_holiday_dates(2020, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f830a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_conversion(data):\n",
    "    import holidays\n",
    "    hotels = data['hotel'].unique()\n",
    "    room_types = data['reserved_room_type'].unique()\n",
    "    expanded_df = pd.DataFrame()\n",
    "    for _, row in data.iterrows():\n",
    "        num_stay_dates = row['total_rns']\n",
    "        try:\n",
    "            # Create a row for each stay date\n",
    "            expanded_booking = pd.DataFrame({\n",
    "                'hotel': row['hotel'],\n",
    "                'room_type': row['reserved_room_type'], \n",
    "                'arrival_date': pd.date_range(start=row['expected_arrival_date'], periods=num_stay_dates),\n",
    "                'total_rns': 1,\n",
    "                'adr': row['adr'],\n",
    "                'room_limit': row['room_limit']\n",
    "            })\n",
    "\n",
    "            # Append the stay date information to the new dataframe\n",
    "            expanded_df = pd.concat([expanded_df, expanded_booking], ignore_index=True)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing booking for {row['hotel']} on {row['expected_arrival_date']} : {num_stay_dates} {e}\")\n",
    "    expanded_df = expanded_df.sort_values('arrival_date')\n",
    "    expanded_df = expanded_df.reset_index(drop=True)\n",
    "    expanded_df['adr']= np.round(expanded_df['adr'], 2)\n",
    "           \n",
    "    expanded_df['dow'] = expanded_df.arrival_date.dt.strftime('%A')\n",
    "    expanded_df['month'] = expanded_df.arrival_date.dt.strftime('%B')\n",
    "\n",
    "    return expanded_df\n",
    "\n",
    "data['total_rns'] = data['stays_in_week_nights'] + data['stays_in_weekend_nights']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['is_canceled'] == 0) & (data['reservation_status'] !='No-Show')] \n",
    "data = data[(data.market_segment != 'Complementary') ]\n",
    "data = data[(data.reserved_room_type == 'A') |(data.reserved_room_type == 'D') | (data.reserved_room_type == 'E')]\n",
    "\n",
    "converted_df = data_conversion(data[['hotel', 'reserved_room_type', 'expected_arrival_date', 'adr', 'room_limit', 'total_rns']])\n",
    "converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310064c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a81421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from snowflake.snowpark.session import Session\n",
    "user = os.getenv(\"user\")\n",
    "warehouse = os.getenv(\"warehouse\")\n",
    "schema= os.getenv(\"schema\")\n",
    "database = os.getenv(\"database\")\n",
    "role =  os.getenv(\"role\")\n",
    "account =  os.getenv(\"account\")\n",
    "password= os.getenv(\"password\")\n",
    "\n",
    "connection_params = dict(user=user, \n",
    "                         password=password, \n",
    "                         account=account, \n",
    "                         warehouse=warehouse, \n",
    "                         database=database,\n",
    "                         schema=schema, \n",
    "                         role=role)\n",
    "\n",
    "session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "session.sql('use warehouse {};'.format(warehouse)).collect()\n",
    "\n",
    "session.sql('use database {};'.format(database)).collect()\n",
    "\n",
    "session.sql('use schema {}.{};'.format(database, schema)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_df[\"arrival_date\"] = pd.to_datetime(converted_df[\"arrival_date\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=session.createDataFrame(\n",
    "        converted_df.values.tolist(),\n",
    "        schema=converted_df.columns.tolist())\n",
    "df_model.write.mode(\"overwrite\").save_as_table(\"TTH_DB.TTH_REV_OPT_Schema.CONVERTED_PRICING_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "537fbc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Function CREATE_PRICING_MODEL successfully created.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''\n",
    "CREATE OR REPLACE PROCEDURE create_pricing_model(table_name STRING)\n",
    "RETURNS STRING\n",
    "LANGUAGE PYTHON\n",
    "RUNTIME_VERSION = '3.8'\n",
    "PACKAGES = ('snowflake-snowpark-python', 'pandas', 'numpy', 'scipy')\n",
    "HANDLER = 'create_pricing_model'\n",
    "AS\n",
    "$$\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar, curve_fit, brentq\n",
    "import itertools\n",
    "def create_pricing_model(session, table_name=None):\n",
    "\n",
    "\n",
    "    # Define functions\n",
    "    def revenue(price):\n",
    "        return price * demand_curve(price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "    def demand_curve(x, a, b, c, d, max_demand):\n",
    "        demand = a * np.exp(-b * x) + c\n",
    "        demand = np.where(x <= max_demand, np.minimum(demand, max_demand), demand)\n",
    "        return demand + d\n",
    "\n",
    "    def demand_to_price(num_rooms, a, b, c, d, max_demand):\n",
    "        def root_func(x):\n",
    "            return num_rooms - (a * np.exp(-b * x) + c)\n",
    "\n",
    "        try:\n",
    "            price = brentq(root_func, 0, 200)\n",
    "        except ValueError:\n",
    "            price_range = (0, 200)\n",
    "            price = np.random.uniform(*price_range)\n",
    "\n",
    "        return price\n",
    "\n",
    "    # Retrieve data from Snowflake table\n",
    "    expanded_df = session.table([table_name]).to_pandas()\n",
    "    expanded_df.columns = map(lambda x: str(x).lower(), expanded_df.columns)\n",
    "\n",
    "    results = pd.DataFrame(columns=['month', 'hotel', 'room_limit', 'room_type', 'dow', 'optimal_rate', 'expected_rn', 'expected_rev', 'optimal_rate_lim_inv'])\n",
    "    hotel_types = ['Resort Hotel', 'City Hotel']\n",
    "    room_types = ['A', 'D', 'E']\n",
    "    daily_rns = expanded_df.groupby(['arrival_date', 'dow', 'month', 'hotel', 'room_type']).agg({'room_limit': 'mean', 'total_rns': 'sum'}).reset_index()\n",
    "    daily_rns = daily_rns.groupby(['dow', 'month', 'hotel', 'room_type']).agg({'room_limit': 'mean', 'total_rns': ['sum', 'mean', 'median']}).reset_index()\n",
    "    daily_rns.columns = ['_'.join(col) for col in daily_rns.columns]\n",
    "    adr_frequency = expanded_df.groupby(['dow', 'month', 'adr', 'hotel', 'room_type']).agg({'room_limit': 'mean', 'total_rns': 'sum'})\n",
    "    adr_frequency.reset_index(inplace=True)\n",
    "    merged_df = pd.merge(adr_frequency, daily_rns, how='left', left_on=['dow', 'month', 'hotel', 'room_type'], right_on=['dow_', 'month_', 'hotel_', 'room_type_'], suffixes=('_act', '_tot'))\n",
    "    merged_df = merged_df.drop(['dow_', 'month_'], axis=1)\n",
    "    merged_df['probability'] = merged_df['total_rns'] / merged_df['total_rns_sum']\n",
    "    merged_df['expected_rns'] = merged_df['probability'] * merged_df['total_rns_median']\n",
    "    merged_df = merged_df.sort_values(by=['dow', 'month', 'adr'], ascending=[True, True, False])\n",
    "    merged_df['expected_demand'] = merged_df.groupby(['dow', 'month'])['expected_rns'].cumsum()\n",
    "    merged_df['expected_rev'] = merged_df['adr'] * merged_df['expected_demand']\n",
    "    results = pd.DataFrame(columns=['month', 'hotel', 'room_limit', 'room_type', 'dow', 'optimal_rate', 'expected_rn', 'expected_rev', 'optimal_rate_lim_inv'])\n",
    "    months = merged_df.month.unique()\n",
    "    dow = merged_df.dow.unique()\n",
    "\n",
    "    for hotel in hotel_types:\n",
    "        for room_type in room_types:\n",
    "            for month in months:\n",
    "                for day in dow:\n",
    "                    data_subset = merged_df[(merged_df['dow'] == day) & (merged_df['hotel'] == hotel) & (merged_df['room_type'] == room_type) & (merged_df['month'] == month)].reset_index()\n",
    "                    if data_subset.empty:\n",
    "                        continue\n",
    "\n",
    "                    mean = data_subset['adr'].mean()\n",
    "                    std_dev = data_subset['adr'].std()\n",
    "                    data_subset['z_scores'] = np.abs((data_subset['adr'] - mean) / std_dev)\n",
    "                    data_subset = data_subset[data_subset['z_scores'] <= 2]\n",
    "\n",
    "                    x_data = data_subset['adr'].values\n",
    "                    y_data = data_subset['expected_demand'].values\n",
    "\n",
    "                    try:\n",
    "                        initial_guess = [1, 0.01, 1, 1, data_subset['total_rns_median'].values[0]]\n",
    "                        bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "                        maxfev = 10000\n",
    "                        params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess, maxfev=maxfev)\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"Error fitting demand curve for {hotel}, {room_type}, {month}, {day}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    a_fit, b_fit, c_fit, d_fit, max_demand = params\n",
    "\n",
    "                    def revenue(price):\n",
    "                        return price * demand_curve(price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    objective = lambda price: -revenue(price)\n",
    "                    optimize = minimize_scalar(objective, bounds=(45, 200), method='bounded')\n",
    "                    optimal_price = optimize.x\n",
    "                    max_revenue = -optimize.fun\n",
    "                    expected_rns = demand_curve(optimal_price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "                    optimal_rate_lim_inv = demand_to_price(data_subset['room_limit'].mean(), a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    new_row = pd.DataFrame({'hotel': hotel, 'room_type': room_type, 'room_limit': data_subset['room_limit'].mean(), 'month': month, 'dow': day, 'optimal_rate': optimal_price, 'expected_rev': max_revenue, 'expected_rn': expected_rns, 'optimal_rate_lim_inv': optimal_rate_lim_inv}, index=[0])\n",
    "                    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "    results['optimal_rate'] = results['optimal_rate'].round()\n",
    "    results['optimal_rate_lim_inv'] = results['optimal_rate_lim_inv'].round()\n",
    "    results['expected_rn'] = results['expected_rn'].round().astype(int)\n",
    "    results['expected_rev'] = results['expected_rev'].round()\n",
    "    combinations = list(itertools.product(hotel_types, room_types))\n",
    "    combinations_df = pd.DataFrame(combinations, columns=['hotel', 'room_type'])\n",
    "    month_dict = {month: index for index, month in enumerate(pd.date_range('2020-01-01', periods=12, freq='M').strftime('%B'), 1)}\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "\n",
    "    for year in range(2020, 2024):\n",
    "        for month in month_dict.values():\n",
    "            start_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1)\n",
    "            end_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1) + pd.offsets.MonthEnd(0)\n",
    "            date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "            df = pd.DataFrame(date_range, columns=['arrival_date'])\n",
    "            df['dow'] = df['arrival_date'].dt.day_name()\n",
    "            df['month'] = df['arrival_date'].dt.month_name()\n",
    "\n",
    "            result_df = df.assign(key=1).merge(combinations_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "            new_data = pd.concat([new_data, result_df], ignore_index=True)\n",
    "\n",
    "    final_data = pd.merge(new_data, results, how='left', on=['dow', 'hotel', 'room_type', 'month'])\n",
    "    final_data['room_limit'] = final_data['room_limit'].astype(int)\n",
    "    final_data['arrival_date'] = pd.to_datetime(final_data['arrival_date']).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    df_model = session.createDataFrame(final_data.values.tolist(), schema=final_data.columns.tolist())\n",
    "    df_model.write.mode(\"overwrite\").save_as_table(\"TTH_DB.TTH_REV_OPT_Schema.PROCESSED_PRICING_DATA\")\n",
    "\n",
    "    return \"Data processed and dumped back to Snowflake\"\n",
    "$$\n",
    "''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2597667",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x7fe0519b7b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(create_pricing_model, name=\"create_pricing_model\",    replace=True,  input_types=[StringType()], return_type=StringType(), packages=['cloudpickle==1.6.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68940338",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.call(\"create_pricing_model\", \"CONVERTED_PRICING_DATA\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3352a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.sql(\"CALL create_pricing_model('CONVERTED_PRICING_DATA')\").collect()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a34d0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='CREATE_PRICING_MODEL successfully dropped.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "session.sql(\"DROP PROCEDURE IF EXISTS CREATE_PRICING_MODEL(String)\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f608ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "account"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
